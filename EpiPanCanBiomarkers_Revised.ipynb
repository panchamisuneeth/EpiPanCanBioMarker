{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZGNdd5NsSsHW",
        "outputId": "a5a15ecd-b97a-4cb0-922c-d8c9d26f5be1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Your runtime has 54.8 gigabytes of available RAM\n",
            "\n",
            "You are using a high-RAM runtime!\n"
          ]
        }
      ],
      "source": [
        "from psutil import virtual_memory\n",
        "ram_gb = virtual_memory().total / 1e9\n",
        "print('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))\n",
        "\n",
        "if ram_gb < 20:\n",
        "  print('Not using a high-RAM runtime')\n",
        "else:\n",
        "  print('You are using a high-RAM runtime!')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ePJoEZ59o99Z",
        "outputId": "e69f3eff-2e11-435a-e339-02c6ac88c447"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "import numpy as np\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kBf88KRYS-1N",
        "outputId": "ae88cc4d-69d3-4eed-8d84-d915732d1e19"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-08-30 12:17:40--  https://gdc-hub.s3.us-east-1.amazonaws.com/download/GDC-PANCAN.survival.tsv\n",
            "Resolving gdc-hub.s3.us-east-1.amazonaws.com (gdc-hub.s3.us-east-1.amazonaws.com)... 3.5.24.161, 16.182.106.218, 52.217.166.202, ...\n",
            "Connecting to gdc-hub.s3.us-east-1.amazonaws.com (gdc-hub.s3.us-east-1.amazonaws.com)|3.5.24.161|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 714013 (697K) [text/tab-separated-values]\n",
            "Saving to: ‘GDC-PANCAN.survival.tsv’\n",
            "\n",
            "GDC-PANCAN.survival 100%[===================>] 697.28K  1.47MB/s    in 0.5s    \n",
            "\n",
            "2024-08-30 12:17:41 (1.47 MB/s) - ‘GDC-PANCAN.survival.tsv’ saved [714013/714013]\n",
            "\n",
            "--2024-08-30 12:17:41--  https://tcga-pancan-atlas-hub.s3.us-east-1.amazonaws.com/download/Survival_SupplementalTable_S1_20171025_xena_sp\n",
            "Resolving tcga-pancan-atlas-hub.s3.us-east-1.amazonaws.com (tcga-pancan-atlas-hub.s3.us-east-1.amazonaws.com)... 16.182.69.210, 52.216.213.122, 52.216.160.70, ...\n",
            "Connecting to tcga-pancan-atlas-hub.s3.us-east-1.amazonaws.com (tcga-pancan-atlas-hub.s3.us-east-1.amazonaws.com)|16.182.69.210|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2419504 (2.3M) [binary/octet-stream]\n",
            "Saving to: ‘Survival_SupplementalTable_S1_20171025_xena_sp’\n",
            "\n",
            "Survival_Supplement 100%[===================>]   2.31M  3.89MB/s    in 0.6s    \n",
            "\n",
            "2024-08-30 12:17:42 (3.89 MB/s) - ‘Survival_SupplementalTable_S1_20171025_xena_sp’ saved [2419504/2419504]\n",
            "\n",
            "--2024-08-30 12:17:42--  https://gdc-hub.s3.us-east-1.amazonaws.com/download/GDC-PANCAN.basic_phenotype.tsv.gz\n",
            "Resolving gdc-hub.s3.us-east-1.amazonaws.com (gdc-hub.s3.us-east-1.amazonaws.com)... 3.5.24.161, 16.182.106.218, 52.217.166.202, ...\n",
            "Connecting to gdc-hub.s3.us-east-1.amazonaws.com (gdc-hub.s3.us-east-1.amazonaws.com)|3.5.24.161|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 203453 (199K) [text/tab-separated-values]\n",
            "Saving to: ‘GDC-PANCAN.basic_phenotype.tsv.gz’\n",
            "\n",
            "GDC-PANCAN.basic_ph 100%[===================>] 198.68K   704KB/s    in 0.3s    \n",
            "\n",
            "2024-08-30 12:17:43 (704 KB/s) - ‘GDC-PANCAN.basic_phenotype.tsv.gz’ saved [203453/203453]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#!wget https://gdc-hub.s3.us-east-1.amazonaws.com/download/GDC-PANCAN.methylation450.tsv.gz\n",
        "!wget https://gdc-hub.s3.us-east-1.amazonaws.com/download/GDC-PANCAN.survival.tsv\n",
        "!wget https://tcga-pancan-atlas-hub.s3.us-east-1.amazonaws.com/download/Survival_SupplementalTable_S1_20171025_xena_sp\n",
        "!wget https://gdc-hub.s3.us-east-1.amazonaws.com/download/GDC-PANCAN.basic_phenotype.tsv.gz\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z7J6TRNboujA",
        "outputId": "342215c6-7347-4ecd-8e80-b8af4802405f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-08-30 12:17:43--  https://gdc-hub.s3.us-east-1.amazonaws.com/download/GDC-PANCAN.methylation27.tsv.gz\n",
            "Resolving gdc-hub.s3.us-east-1.amazonaws.com (gdc-hub.s3.us-east-1.amazonaws.com)... 3.5.24.161, 16.182.106.218, 52.217.166.202, ...\n",
            "Connecting to gdc-hub.s3.us-east-1.amazonaws.com (gdc-hub.s3.us-east-1.amazonaws.com)|3.5.24.161|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 536909692 (512M) [text/tab-separated-values]\n",
            "Saving to: ‘GDC-PANCAN.methylation27.tsv.gz’\n",
            "\n",
            "GDC-PANCAN.methylat 100%[===================>] 512.04M  19.3MB/s    in 28s     \n",
            "\n",
            "2024-08-30 12:18:11 (18.5 MB/s) - ‘GDC-PANCAN.methylation27.tsv.gz’ saved [536909692/536909692]\n",
            "\n",
            "--2024-08-30 12:18:12--  https://gdc-hub.s3.us-east-1.amazonaws.com/download/GDC-PANCAN.htseq_fpkm-uq.tsv.gz\n",
            "Resolving gdc-hub.s3.us-east-1.amazonaws.com (gdc-hub.s3.us-east-1.amazonaws.com)... 52.216.33.114, 3.5.16.85, 52.217.229.210, ...\n",
            "Connecting to gdc-hub.s3.us-east-1.amazonaws.com (gdc-hub.s3.us-east-1.amazonaws.com)|52.216.33.114|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 3357673705 (3.1G) [text/tab-separated-values]\n",
            "Saving to: ‘GDC-PANCAN.htseq_fpkm-uq.tsv.gz’\n",
            "\n",
            "GDC-PANCAN.htseq_fp 100%[===================>]   3.13G  20.9MB/s    in 2m 38s  \n",
            "\n",
            "2024-08-30 12:20:50 (20.3 MB/s) - ‘GDC-PANCAN.htseq_fpkm-uq.tsv.gz’ saved [3357673705/3357673705]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://gdc-hub.s3.us-east-1.amazonaws.com/download/GDC-PANCAN.methylation27.tsv.gz\n",
        "!wget https://gdc-hub.s3.us-east-1.amazonaws.com/download/GDC-PANCAN.htseq_fpkm-uq.tsv.gz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ST9FFT7iTI1T",
        "outputId": "061cc55d-447c-4580-8b57-845333d9a025"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(18492, 3)\n",
            "(19188, 7)\n",
            "Index(['Composite Element REF', 'TCGA-A2-A0EQ-01A', 'TCGA-A8-A081-01A',\n",
            "       'TCGA-E2-A14T-01A', 'TCGA-A8-A09K-01A', 'TCGA-AN-A04C-01A',\n",
            "       'TCGA-A8-A07B-01A', 'TCGA-A2-A0CP-01A', 'TCGA-A8-A07S-01A',\n",
            "       'TCGA-AO-A12H-01A',\n",
            "       ...\n",
            "       'TCGA-BG-A0M7-01A', 'TCGA-A5-A0R9-01A', 'TCGA-AX-A0IU-01A',\n",
            "       'TCGA-A5-A0R8-01A', 'TCGA-AP-A05H-01A', 'TCGA-B5-A0JN-01A',\n",
            "       'TCGA-BG-A0M3-01A', 'TCGA-BK-A0CC-01A', 'TCGA-B5-A0K2-01A',\n",
            "       'TCGA-AX-A06F-01A'],\n",
            "      dtype='object', length=2596)\n",
            "Index(['TCGA-OR-A5JP-01A', 'TCGA-OR-A5JE-01A', 'TCGA-OR-A5JG-01A',\n",
            "       'TCGA-OR-A5L9-01A', 'TCGA-OR-A5JR-01A', 'TCGA-OR-A5KU-01A',\n",
            "       'TCGA-OR-A5LS-01A', 'TCGA-OR-A5J7-01A', 'TCGA-OR-A5JQ-01A',\n",
            "       'TCGA-OR-A5JS-01A',\n",
            "       ...\n",
            "       'TARGET-50-PAJMKJ-01A', 'TARGET-50-CAAAAQ-11A', 'TARGET-50-PAKSCC-01A',\n",
            "       'TARGET-50-PAJNSL-11A', 'TARGET-50-PAJPAU-01A', 'TARGET-50-PAJNZU-01A',\n",
            "       'TARGET-50-PAJNNR-01A', 'TARGET-50-PAJNTJ-02A', 'TARGET-50-PAECJB-01A',\n",
            "       'TARGET-50-PALFRD-01A'],\n",
            "      dtype='object', length=11768)\n",
            "TCGA-LUAD\n",
            "%%%%%%%%%%%%%%%%%%\n",
            "Control Samples :0\n",
            "Tumour Samples :64\n",
            "TCGA-BRCA\n",
            "%%%%%%%%%%%%%%%%%%\n",
            "Control Samples :21\n",
            "Tumour Samples :312\n",
            "TCGA-UCEC\n",
            "%%%%%%%%%%%%%%%%%%\n",
            "Control Samples :1\n",
            "Tumour Samples :116\n",
            "TARGET-AML\n",
            "%%%%%%%%%%%%%%%%%%\n",
            "Control Samples :0\n",
            "Tumour Samples :0\n",
            "TCGA-OV\n",
            "%%%%%%%%%%%%%%%%%%\n",
            "Control Samples :0\n",
            "Tumour Samples :372\n",
            "TCGA-LUSC\n",
            "%%%%%%%%%%%%%%%%%%\n",
            "Control Samples :0\n",
            "Tumour Samples :130\n",
            "TCGA-HNSC\n",
            "%%%%%%%%%%%%%%%%%%\n",
            "Control Samples :0\n",
            "Tumour Samples :0\n",
            "TCGA-KIRC\n",
            "%%%%%%%%%%%%%%%%%%\n",
            "Control Samples :0\n",
            "Tumour Samples :213\n",
            "TCGA-CESC\n",
            "%%%%%%%%%%%%%%%%%%\n",
            "Control Samples :0\n",
            "Tumour Samples :0\n",
            "TARGET-WT\n",
            "%%%%%%%%%%%%%%%%%%\n",
            "Control Samples :0\n",
            "Tumour Samples :0\n",
            "TCGA-LAML\n",
            "%%%%%%%%%%%%%%%%%%\n",
            "Control Samples :0\n",
            "Tumour Samples :100\n",
            "TCGA-PRAD\n",
            "%%%%%%%%%%%%%%%%%%\n",
            "Control Samples :0\n",
            "Tumour Samples :0\n",
            "TARGET-NBL\n",
            "%%%%%%%%%%%%%%%%%%\n",
            "Control Samples :0\n",
            "Tumour Samples :0\n",
            "TCGA-GBM\n",
            "%%%%%%%%%%%%%%%%%%\n",
            "Control Samples :0\n",
            "Tumour Samples :77\n",
            "TCGA-PAAD\n",
            "%%%%%%%%%%%%%%%%%%\n",
            "Control Samples :0\n",
            "Tumour Samples :0\n",
            "TCGA-BLCA\n",
            "%%%%%%%%%%%%%%%%%%\n",
            "Control Samples :0\n",
            "Tumour Samples :0\n",
            "TCGA-SARC\n",
            "%%%%%%%%%%%%%%%%%%\n",
            "Control Samples :0\n",
            "Tumour Samples :0\n",
            "TCGA-THCA\n",
            "%%%%%%%%%%%%%%%%%%\n",
            "Control Samples :0\n",
            "Tumour Samples :0\n",
            "TCGA-KIRP\n",
            "%%%%%%%%%%%%%%%%%%\n",
            "Control Samples :0\n",
            "Tumour Samples :15\n",
            "TCGA-UVM\n",
            "%%%%%%%%%%%%%%%%%%\n",
            "Control Samples :0\n",
            "Tumour Samples :0\n",
            "TCGA-LIHC\n",
            "%%%%%%%%%%%%%%%%%%\n",
            "Control Samples :0\n",
            "Tumour Samples :0\n",
            "TCGA-SKCM\n",
            "%%%%%%%%%%%%%%%%%%\n",
            "Control Samples :0\n",
            "Tumour Samples :0\n",
            "TCGA-ACC\n",
            "%%%%%%%%%%%%%%%%%%\n",
            "Control Samples :0\n",
            "Tumour Samples :0\n",
            "TCGA-LGG\n",
            "%%%%%%%%%%%%%%%%%%\n",
            "Control Samples :0\n",
            "Tumour Samples :0\n",
            "TCGA-STAD\n",
            "%%%%%%%%%%%%%%%%%%\n",
            "Control Samples :0\n",
            "Tumour Samples :37\n",
            "nan\n",
            "%%%%%%%%%%%%%%%%%%\n",
            "Control Samples :0\n",
            "Tumour Samples :0\n",
            "TCGA-PCPG\n",
            "%%%%%%%%%%%%%%%%%%\n",
            "Control Samples :0\n",
            "Tumour Samples :0\n",
            "TCGA-TGCT\n",
            "%%%%%%%%%%%%%%%%%%\n",
            "Control Samples :0\n",
            "Tumour Samples :0\n",
            "TCGA-COAD\n",
            "%%%%%%%%%%%%%%%%%%\n",
            "Control Samples :12\n",
            "Tumour Samples :163\n",
            "TCGA-THYM\n",
            "%%%%%%%%%%%%%%%%%%\n",
            "Control Samples :0\n",
            "Tumour Samples :0\n",
            "TCGA-KICH\n",
            "%%%%%%%%%%%%%%%%%%\n",
            "Control Samples :0\n",
            "Tumour Samples :0\n",
            "TCGA-ESCA\n",
            "%%%%%%%%%%%%%%%%%%\n",
            "Control Samples :0\n",
            "Tumour Samples :0\n",
            "TCGA-UCS\n",
            "%%%%%%%%%%%%%%%%%%\n",
            "Control Samples :0\n",
            "Tumour Samples :0\n",
            "TARGET-ALL-P3\n",
            "%%%%%%%%%%%%%%%%%%\n",
            "Control Samples :0\n",
            "Tumour Samples :0\n",
            "TCGA-READ\n",
            "%%%%%%%%%%%%%%%%%%\n",
            "Control Samples :4\n",
            "Tumour Samples :67\n",
            "TARGET-OS\n",
            "%%%%%%%%%%%%%%%%%%\n",
            "Control Samples :0\n",
            "Tumour Samples :0\n",
            "TARGET-RT\n",
            "%%%%%%%%%%%%%%%%%%\n",
            "Control Samples :0\n",
            "Tumour Samples :0\n",
            "TCGA-MESO\n",
            "%%%%%%%%%%%%%%%%%%\n",
            "Control Samples :0\n",
            "Tumour Samples :0\n",
            "TCGA-DLBC\n",
            "%%%%%%%%%%%%%%%%%%\n",
            "Control Samples :0\n",
            "Tumour Samples :0\n",
            "TCGA-CHOL\n",
            "%%%%%%%%%%%%%%%%%%\n",
            "Control Samples :0\n",
            "Tumour Samples :0\n",
            "TARGET-CCSK\n",
            "%%%%%%%%%%%%%%%%%%\n",
            "Control Samples :0\n",
            "Tumour Samples :0\n",
            "Pan Control Samples :38\n",
            "Pan Tumour Samples :1666\n",
            "          disease  cancer_samples  normal samples\n",
            "0       TCGA-LUAD              64               0\n",
            "1       TCGA-BRCA             312              21\n",
            "2       TCGA-UCEC             116               1\n",
            "3      TARGET-AML               0               0\n",
            "4         TCGA-OV             372               0\n",
            "5       TCGA-LUSC             130               0\n",
            "6       TCGA-HNSC               0               0\n",
            "7       TCGA-KIRC             213               0\n",
            "8       TCGA-CESC               0               0\n",
            "9       TARGET-WT               0               0\n",
            "10      TCGA-LAML             100               0\n",
            "11      TCGA-PRAD               0               0\n",
            "12     TARGET-NBL               0               0\n",
            "13       TCGA-GBM              77               0\n",
            "14      TCGA-PAAD               0               0\n",
            "15      TCGA-BLCA               0               0\n",
            "16      TCGA-SARC               0               0\n",
            "17      TCGA-THCA               0               0\n",
            "18      TCGA-KIRP              15               0\n",
            "19       TCGA-UVM               0               0\n",
            "20      TCGA-LIHC               0               0\n",
            "21      TCGA-SKCM               0               0\n",
            "22       TCGA-ACC               0               0\n",
            "23       TCGA-LGG               0               0\n",
            "24      TCGA-STAD              37               0\n",
            "25            NaN               0               0\n",
            "26      TCGA-PCPG               0               0\n",
            "27      TCGA-TGCT               0               0\n",
            "28      TCGA-COAD             163              12\n",
            "29      TCGA-THYM               0               0\n",
            "30      TCGA-KICH               0               0\n",
            "31      TCGA-ESCA               0               0\n",
            "32       TCGA-UCS               0               0\n",
            "33  TARGET-ALL-P3               0               0\n",
            "34      TCGA-READ              67               4\n",
            "35      TARGET-OS               0               0\n",
            "36      TARGET-RT               0               0\n",
            "37      TCGA-MESO               0               0\n",
            "38      TCGA-DLBC               0               0\n",
            "39      TCGA-CHOL               0               0\n",
            "40    TARGET-CCSK               0               0\n"
          ]
        }
      ],
      "source": [
        "surv = pd.read_csv('Survival_SupplementalTable_S1_20171025_xena_sp', sep='\\t')\n",
        "meta_df = pd.read_csv('GDC-PANCAN.basic_phenotype.tsv.gz', sep='\\t')\n",
        "meth_cols = pd.read_csv('GDC-PANCAN.methylation27.tsv.gz', compression='gzip', sep='\\t',nrows=0).columns\n",
        "ge_cols = pd.read_csv('GDC-PANCAN.htseq_fpkm-uq.tsv.gz',compression='gzip', sep='\\t', index_col=0, nrows=0).columns\n",
        "surv_gdc = pd.read_csv('GDC-PANCAN.survival.tsv' , sep='\\t')\n",
        "surv_gdc = surv_gdc.set_index('sample')\n",
        "print(surv_gdc.shape)\n",
        "print(meta_df.shape)\n",
        "meta_df = meta_df.set_index('sample')\n",
        "gdc = meta_df.join(surv_gdc).reset_index()\n",
        "gdc = gdc.set_index('_PATIENT')\n",
        "surv = surv.set_index('_PATIENT')\n",
        "gdc.rename(columns= {'OS': 'OS1', 'OS.time':'OS1.time'}, inplace = True)\n",
        "gdc.rename(columns= {'sample': 'sample1'},inplace = True)\n",
        "surv_gdc = pd.merge(gdc, surv, left_index=True, right_index=True)\n",
        "surv_gdc = surv_gdc.dropna(axis=0, how='all')\n",
        "surv_gdc.reset_index()\n",
        "surv_gdc = surv_gdc.set_index('sample1')\n",
        "print(meth_cols)\n",
        "print(ge_cols)\n",
        "## Metafile analysis\n",
        "## Meta file analysis and label dictionary creation\n",
        "\n",
        "c_list=[]\n",
        "rs_list=[]\n",
        "key_control = ['Blood Derived Normal','Bone Marrow Normal','Buccal Cell Normal','FFPE Scrolls','Solid Tissue Normal' ]\n",
        "key_case = ['Additional - New Primary', 'Additional Metastatic','Human Tumor Original Cells','Metastatic','Primary Blood Derived Cancer - Bone Marrow','Primary Blood Derived Cancer - Peripheral Blood','Primary Tumor','Recurrent Blood Derived Cancer - Bone Marrow','Recurrent Blood Derived Cancer - Peripheral Blood','Recurrent Tumor']\n",
        "meta_df_control = meta_df[meta_df['sample_type'].isin(key_control)]\n",
        "meta_df_case = meta_df[meta_df['sample_type'].isin(key_case)]\n",
        "label_dict = {}\n",
        "s1 = list(set(meta_df_control.index) & set(ge_cols) & set(meth_cols))\n",
        "pan_key_normal = []\n",
        "pan_key_cancer = []\n",
        "for k in s1:\n",
        "  label_dict[k] = \"C\"\n",
        "s2 = list(set(meta_df_case.index) &set(ge_cols) & set(meth_cols))\n",
        "for k in s2:\n",
        "  label_dict[k] = \"RS\"\n",
        "\n",
        "## Finding normal and tumor samples in different cancers\n",
        "##  dis_list --> s_tcga : [{key1:value1,key2:value2}]\n",
        "s_tcga = {}\n",
        "dis_list = meta_df['project_id'].unique()\n",
        "for dis in dis_list:\n",
        "  print(dis)\n",
        "  print(\"%%%%%%%%%%%%%%%%%%\")\n",
        "  key_normal = []\n",
        "  key_nan = []\n",
        "  key_cancer = []\n",
        "\n",
        "  meta_df1 = meta_df[meta_df['project_id'] == dis]\n",
        "  meta_df1.reset_index(inplace = True)\n",
        "  s_tcga_i ={}\n",
        "  for i in range(0,meta_df1.shape[0]):\n",
        "    if meta_df1['sample_type'][i] in key_control:\n",
        "      key_normal.append(meta_df1['sample'][i])\n",
        "      pan_key_normal.append(meta_df1['sample'][i])\n",
        "    elif pd.isnull(meta_df1['sample_type'][i]):\n",
        "      key_nan.append(meta_df1['sample'][i])\n",
        "    else:\n",
        "      key_cancer.append(meta_df1['sample'][i])\n",
        "      pan_key_cancer.append(meta_df1['sample'][i])\n",
        "\n",
        "  samples_to_use_i = []\n",
        "  samples_to_use_i = key_normal + key_cancer\n",
        "  key_normal = set(ge_cols) & set(meth_cols) & set(key_normal)\n",
        "  key_normal = list(key_normal)\n",
        "  key_cancer =  set(ge_cols) & set(meth_cols) & set(key_cancer)\n",
        "  key_cancer = list(key_cancer)\n",
        "\n",
        "  pan_key_normal = set(ge_cols) & set(meth_cols) & set(pan_key_normal)\n",
        "  pan_key_normal = list(pan_key_normal)\n",
        "  pan_key_cancer =  set(ge_cols) & set(meth_cols) & set(pan_key_cancer)\n",
        "  pan_key_cancer = list(pan_key_cancer)\n",
        "  s_tcga_i['normal'] = key_normal\n",
        "  s_tcga_i['cancer'] = key_cancer\n",
        "  if len(samples_to_use_i) != 0 :\n",
        "    s_tcga[dis] = s_tcga_i\n",
        "\n",
        "  C_count = len(key_normal)\n",
        "  c_list.append(C_count)\n",
        "  print(f\"Control Samples :{C_count}\")\n",
        "  RS_count = len(key_cancer)\n",
        "  rs_list.append(RS_count)\n",
        "  print(f\"Tumour Samples :{RS_count}\")\n",
        "C_count = len(pan_key_normal)\n",
        "print(f\"Pan Control Samples :{C_count}\")\n",
        "RS_count = len(pan_key_cancer)\n",
        "print(f\"Pan Tumour Samples :{RS_count}\")\n",
        "c_dict = {\n",
        "  \"disease\": dis_list,\n",
        "  \"cancer_samples\": rs_list,\n",
        "  \"normal samples\": c_list\n",
        "}\n",
        "c_df = pd.DataFrame(c_dict)\n",
        "print(c_df)\n",
        "\n",
        "#c_df.to_csv(\"/content/drive/MyDrive/phd/disease_sample_count.csv\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WCothtlee7Th",
        "outputId": "1c2b4a3d-fae5-4e67-93ef-fd0578bdba2f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample Size\n",
            "1704\n"
          ]
        }
      ],
      "source": [
        "## Sample selection\n",
        "samples_to_use = pan_key_normal + pan_key_cancer\n",
        "samples_to_use = list(samples_to_use)\n",
        "print(\"Sample Size\")\n",
        "print(len(samples_to_use))\n",
        "#pd.DataFrame(samples_to_use).to_csv(\"/content/drive/MyDrive/phd/s_gdc.csv\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WefyXykJqwkJ",
        "outputId": "eb8a6990-b48c-426a-8415-e8497446761b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "import gc\n",
        "gc.collect()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yEu2bzWB_X8D",
        "outputId": "6ab4fdc0-635e-4f49-fcfa-03b34ce45846"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-08-30 12:20:54--  https://gdc-hub.s3.us-east-1.amazonaws.com/download/gencode.v22.annotation.gene.probeMap\n",
            "Resolving gdc-hub.s3.us-east-1.amazonaws.com (gdc-hub.s3.us-east-1.amazonaws.com)... 52.216.113.206, 52.216.222.178, 52.217.89.192, ...\n",
            "Connecting to gdc-hub.s3.us-east-1.amazonaws.com (gdc-hub.s3.us-east-1.amazonaws.com)|52.216.113.206|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 3243193 (3.1M) [binary/octet-stream]\n",
            "Saving to: ‘gencode.v22.annotation.gene.probeMap’\n",
            "\n",
            "gencode.v22.annotat 100%[===================>]   3.09M  5.16MB/s    in 0.6s    \n",
            "\n",
            "2024-08-30 12:20:55 (5.16 MB/s) - ‘gencode.v22.annotation.gene.probeMap’ saved [3243193/3243193]\n",
            "\n",
            "--2024-08-30 12:20:55--  https://gdc-hub.s3.us-east-1.amazonaws.com/download/illuminaMethyl27_hg38_GDC\n",
            "Resolving gdc-hub.s3.us-east-1.amazonaws.com (gdc-hub.s3.us-east-1.amazonaws.com)... 52.216.113.206, 52.216.222.178, 52.217.89.192, ...\n",
            "Connecting to gdc-hub.s3.us-east-1.amazonaws.com (gdc-hub.s3.us-east-1.amazonaws.com)|52.216.113.206|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1296655 (1.2M) [binary/octet-stream]\n",
            "Saving to: ‘illuminaMethyl27_hg38_GDC’\n",
            "\n",
            "illuminaMethyl27_hg 100%[===================>]   1.24M  2.41MB/s    in 0.5s    \n",
            "\n",
            "2024-08-30 12:20:56 (2.41 MB/s) - ‘illuminaMethyl27_hg38_GDC’ saved [1296655/1296655]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "### Creating dictionaries\n",
        "!wget https://gdc-hub.s3.us-east-1.amazonaws.com/download/gencode.v22.annotation.gene.probeMap\n",
        "!wget https://gdc-hub.s3.us-east-1.amazonaws.com/download/illuminaMethyl27_hg38_GDC"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "miILj8nVfpnc"
      },
      "outputs": [],
      "source": [
        "map={}\n",
        "meth_map = pd.read_csv('illuminaMethyl27_hg38_GDC', sep='\\t')\n",
        "map_dict_m = dict(zip(meth_map['#id'], meth_map['gene']))\n",
        "map_mm = pd.read_csv('/content/drive/MyDrive/phd/cpg_methylation_cpg_to_annotation.tsv', sep='\\t')\n",
        "map_dict_mm = dict(zip(map_mm['CpG_id'], map_mm['Symbol']))\n",
        "for (i,j) in map_dict_mm.items():\n",
        "  if pd.isnull(j) or j=='.':\n",
        "    map[i]=map_dict_m[i]\n",
        "  else:\n",
        "    k = map_dict_m[i]\n",
        "    k_new = list(k.split(','))\n",
        "    h = map_dict_mm[i]\n",
        "    h_new = list(h.split(','))\n",
        "    unique_values = set(k_new + h_new)\n",
        "    if '.' in unique_values:\n",
        "      unique_values.remove('.')\n",
        "    map[i]=unique_values\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CLh-y8YjSlWX",
        "outputId": "90c96d32-26b0-4775-aa2f-3564f3fcfbf6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting keras-tuner\n",
            "  Downloading keras_tuner-1.4.7-py3-none-any.whl.metadata (5.4 kB)\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.10/dist-packages (from keras-tuner) (3.4.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from keras-tuner) (24.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from keras-tuner) (2.32.3)\n",
            "Collecting kt-legacy (from keras-tuner)\n",
            "  Downloading kt_legacy-1.0.5-py3-none-any.whl.metadata (221 bytes)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from keras->keras-tuner) (1.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from keras->keras-tuner) (1.26.4)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras->keras-tuner) (13.8.0)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.10/dist-packages (from keras->keras-tuner) (0.0.8)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.10/dist-packages (from keras->keras-tuner) (3.11.0)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.10/dist-packages (from keras->keras-tuner) (0.12.1)\n",
            "Requirement already satisfied: ml-dtypes in /usr/local/lib/python3.10/dist-packages (from keras->keras-tuner) (0.4.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->keras-tuner) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->keras-tuner) (3.8)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->keras-tuner) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->keras-tuner) (2024.7.4)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.10/dist-packages (from optree->keras->keras-tuner) (4.12.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras->keras-tuner) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras->keras-tuner) (2.16.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras->keras-tuner) (0.1.2)\n",
            "Downloading keras_tuner-1.4.7-py3-none-any.whl (129 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.1/129.1 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading kt_legacy-1.0.5-py3-none-any.whl (9.6 kB)\n",
            "Installing collected packages: kt-legacy, keras-tuner\n",
            "Successfully installed keras-tuner-1.4.7 kt-legacy-1.0.5\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image,ImageOps,ImageEnhance\n",
        "from glob import glob\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import metrics\n",
        "\n",
        "import cv2\n",
        "import gc\n",
        "import os\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras import layers\n",
        "from tensorflow.keras import activations\n",
        "from io import BytesIO\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "from tensorflow.keras import datasets,layers,models,Sequential\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.layers import Dense, Conv2D, Flatten, MaxPooling2D\n",
        "from tensorflow.keras.preprocessing.image import img_to_array\n",
        "!pip install keras-tuner\n",
        "import keras_tuner as kt\n",
        "from tensorflow import keras\n",
        "import tensorflow as tf\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_q5k6uPPTnvf"
      },
      "outputs": [],
      "source": [
        "ge = pd.read_csv('GDC-PANCAN.htseq_fpkm-uq.tsv.gz', compression='gzip', index_col=0, sep ='\\t')\n",
        "ge = ge.T"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G9lUQrewRulS",
        "outputId": "0684a014-dff4-4ce1-d152-f8ddaeaf9182"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(11768, 60483)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "ge.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 342
        },
        "id": "tIFkrXKujP_y",
        "outputId": "91e2ab65-164b-458c-cabd-a64463fb98ed"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "xena_sample       ENSG00000242268.2  ENSG00000270112.3  ENSG00000167578.15  \\\n",
              "TCGA-OR-A5JP-01A           0.000000          10.689655           18.536987   \n",
              "TCGA-OR-A5JE-01A           0.000000          14.408626           18.684183   \n",
              "TCGA-OR-A5JG-01A           0.000000          14.022621           17.334107   \n",
              "TCGA-OR-A5L9-01A           0.000000          11.291444           19.713465   \n",
              "TCGA-OR-A5JR-01A           9.486642          10.221394           16.761630   \n",
              "\n",
              "xena_sample       ENSG00000273842.1  ENSG00000078237.5  ENSG00000146083.10  \\\n",
              "TCGA-OR-A5JP-01A                0.0          17.847476           17.092449   \n",
              "TCGA-OR-A5JE-01A                0.0          18.227483           17.161078   \n",
              "TCGA-OR-A5JG-01A                0.0          17.287893           18.260739   \n",
              "TCGA-OR-A5L9-01A                0.0          16.722624           18.003351   \n",
              "TCGA-OR-A5JR-01A                0.0          17.157762           19.528297   \n",
              "\n",
              "xena_sample       ENSG00000225275.4  ENSG00000158486.12  ENSG00000198242.12  \\\n",
              "TCGA-OR-A5JP-01A           0.000000            7.645763           21.628175   \n",
              "TCGA-OR-A5JE-01A           0.000000            5.543363           22.489617   \n",
              "TCGA-OR-A5JG-01A           0.000000            7.634078           21.877272   \n",
              "TCGA-OR-A5L9-01A           0.000000            0.000000           21.095333   \n",
              "TCGA-OR-A5JR-01A          10.817554            6.108544           20.356000   \n",
              "\n",
              "xena_sample       ENSG00000259883.1  ...  ENSG00000238244.3  \\\n",
              "TCGA-OR-A5JP-01A          10.917522  ...                0.0   \n",
              "TCGA-OR-A5JE-01A           0.000000  ...                0.0   \n",
              "TCGA-OR-A5JG-01A          10.584045  ...                0.0   \n",
              "TCGA-OR-A5L9-01A           0.000000  ...                0.0   \n",
              "TCGA-OR-A5JR-01A          10.951409  ...                0.0   \n",
              "\n",
              "xena_sample       ENSG00000186115.11  ENSG00000216352.1  ENSG00000267117.1  \\\n",
              "TCGA-OR-A5JP-01A            0.000000                0.0          12.722942   \n",
              "TCGA-OR-A5JE-01A            8.766763                0.0           0.000000   \n",
              "TCGA-OR-A5JG-01A            0.000000                0.0          12.711200   \n",
              "TCGA-OR-A5L9-01A            0.000000                0.0          13.827415   \n",
              "TCGA-OR-A5JR-01A            7.347722                0.0          12.979204   \n",
              "\n",
              "xena_sample       ENSG00000273233.1  ENSG00000105063.17  ENSG00000231119.2  \\\n",
              "TCGA-OR-A5JP-01A          11.773066           19.730227          11.102080   \n",
              "TCGA-OR-A5JE-01A          12.968313           18.747937          13.367429   \n",
              "TCGA-OR-A5JG-01A          12.439242           19.723083          11.675085   \n",
              "TCGA-OR-A5L9-01A           0.000000           18.493479          13.376072   \n",
              "TCGA-OR-A5JR-01A           0.000000           18.643556          12.720505   \n",
              "\n",
              "xena_sample       ENSG00000280861.1  ENSG00000123685.7  ENSG00000181518.3  \n",
              "TCGA-OR-A5JP-01A                0.0          11.102346           0.000000  \n",
              "TCGA-OR-A5JE-01A                0.0          13.675791           9.005429  \n",
              "TCGA-OR-A5JG-01A                0.0          10.938679           0.000000  \n",
              "TCGA-OR-A5L9-01A                0.0          13.528328           0.000000  \n",
              "TCGA-OR-A5JR-01A                0.0          12.505076           0.000000  \n",
              "\n",
              "[5 rows x 60483 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-3fbf326b-0898-4a0a-ae91-de47b682e874\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>xena_sample</th>\n",
              "      <th>ENSG00000242268.2</th>\n",
              "      <th>ENSG00000270112.3</th>\n",
              "      <th>ENSG00000167578.15</th>\n",
              "      <th>ENSG00000273842.1</th>\n",
              "      <th>ENSG00000078237.5</th>\n",
              "      <th>ENSG00000146083.10</th>\n",
              "      <th>ENSG00000225275.4</th>\n",
              "      <th>ENSG00000158486.12</th>\n",
              "      <th>ENSG00000198242.12</th>\n",
              "      <th>ENSG00000259883.1</th>\n",
              "      <th>...</th>\n",
              "      <th>ENSG00000238244.3</th>\n",
              "      <th>ENSG00000186115.11</th>\n",
              "      <th>ENSG00000216352.1</th>\n",
              "      <th>ENSG00000267117.1</th>\n",
              "      <th>ENSG00000273233.1</th>\n",
              "      <th>ENSG00000105063.17</th>\n",
              "      <th>ENSG00000231119.2</th>\n",
              "      <th>ENSG00000280861.1</th>\n",
              "      <th>ENSG00000123685.7</th>\n",
              "      <th>ENSG00000181518.3</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>TCGA-OR-A5JP-01A</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>10.689655</td>\n",
              "      <td>18.536987</td>\n",
              "      <td>0.0</td>\n",
              "      <td>17.847476</td>\n",
              "      <td>17.092449</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>7.645763</td>\n",
              "      <td>21.628175</td>\n",
              "      <td>10.917522</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>12.722942</td>\n",
              "      <td>11.773066</td>\n",
              "      <td>19.730227</td>\n",
              "      <td>11.102080</td>\n",
              "      <td>0.0</td>\n",
              "      <td>11.102346</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>TCGA-OR-A5JE-01A</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>14.408626</td>\n",
              "      <td>18.684183</td>\n",
              "      <td>0.0</td>\n",
              "      <td>18.227483</td>\n",
              "      <td>17.161078</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>5.543363</td>\n",
              "      <td>22.489617</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>8.766763</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>12.968313</td>\n",
              "      <td>18.747937</td>\n",
              "      <td>13.367429</td>\n",
              "      <td>0.0</td>\n",
              "      <td>13.675791</td>\n",
              "      <td>9.005429</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>TCGA-OR-A5JG-01A</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>14.022621</td>\n",
              "      <td>17.334107</td>\n",
              "      <td>0.0</td>\n",
              "      <td>17.287893</td>\n",
              "      <td>18.260739</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>7.634078</td>\n",
              "      <td>21.877272</td>\n",
              "      <td>10.584045</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>12.711200</td>\n",
              "      <td>12.439242</td>\n",
              "      <td>19.723083</td>\n",
              "      <td>11.675085</td>\n",
              "      <td>0.0</td>\n",
              "      <td>10.938679</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>TCGA-OR-A5L9-01A</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>11.291444</td>\n",
              "      <td>19.713465</td>\n",
              "      <td>0.0</td>\n",
              "      <td>16.722624</td>\n",
              "      <td>18.003351</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>21.095333</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>13.827415</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>18.493479</td>\n",
              "      <td>13.376072</td>\n",
              "      <td>0.0</td>\n",
              "      <td>13.528328</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>TCGA-OR-A5JR-01A</th>\n",
              "      <td>9.486642</td>\n",
              "      <td>10.221394</td>\n",
              "      <td>16.761630</td>\n",
              "      <td>0.0</td>\n",
              "      <td>17.157762</td>\n",
              "      <td>19.528297</td>\n",
              "      <td>10.817554</td>\n",
              "      <td>6.108544</td>\n",
              "      <td>20.356000</td>\n",
              "      <td>10.951409</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>7.347722</td>\n",
              "      <td>0.0</td>\n",
              "      <td>12.979204</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>18.643556</td>\n",
              "      <td>12.720505</td>\n",
              "      <td>0.0</td>\n",
              "      <td>12.505076</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 60483 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3fbf326b-0898-4a0a-ae91-de47b682e874')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-3fbf326b-0898-4a0a-ae91-de47b682e874 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-3fbf326b-0898-4a0a-ae91-de47b682e874');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-67258d18-f277-46c3-aa0d-8a56b1795b67\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-67258d18-f277-46c3-aa0d-8a56b1795b67')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-67258d18-f277-46c3-aa0d-8a56b1795b67 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "ge"
            }
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "ge.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m0Vsut_SxH9L"
      },
      "source": [
        "### GE DATA + TUMOR/NORMAL"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ge.index"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xy9U6HB9aooL",
        "outputId": "7ae2bf64-2bb4-42ff-be1b-4fb121e6a2dd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['TCGA-OR-A5JP-01A', 'TCGA-OR-A5JE-01A', 'TCGA-OR-A5JG-01A',\n",
              "       'TCGA-OR-A5L9-01A', 'TCGA-OR-A5JR-01A', 'TCGA-OR-A5KU-01A',\n",
              "       'TCGA-OR-A5LS-01A', 'TCGA-OR-A5J7-01A', 'TCGA-OR-A5JQ-01A',\n",
              "       'TCGA-OR-A5JS-01A',\n",
              "       ...\n",
              "       'TARGET-50-PAJMKJ-01A', 'TARGET-50-CAAAAQ-11A', 'TARGET-50-PAKSCC-01A',\n",
              "       'TARGET-50-PAJNSL-11A', 'TARGET-50-PAJPAU-01A', 'TARGET-50-PAJNZU-01A',\n",
              "       'TARGET-50-PAJNNR-01A', 'TARGET-50-PAJNTJ-02A', 'TARGET-50-PAECJB-01A',\n",
              "       'TARGET-50-PALFRD-01A'],\n",
              "      dtype='object', length=11768)"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m1wVw_nGRZ0M"
      },
      "outputs": [],
      "source": [
        "label_dict={}\n",
        "s1 = list(set(meta_df_control.index) & set(ge.index))\n",
        "for k in s1:\n",
        "  label_dict[k] = \"C\"\n",
        "s2 = s1 = list(set(meta_df_case.index) & set(ge.index))\n",
        "for k in s2:\n",
        "  label_dict[k] = \"RS\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dXZhLezSUvhr",
        "outputId": "655ae866-4af3-479f-b486-44fc96941b2d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(11768, 60483)"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "ge.shape"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "l_gid = pd.read_csv(\"/content/drive/MyDrive/phd/l_gid.csv\")\n",
        "l_gid = list(l_gid['0'])\n",
        "len(l_gid)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g9jz20_9ljHB",
        "outputId": "ae7c7e20-670f-4bdd-8c26-a58c27d99c24"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "115"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hdlMSBCZeN7O"
      },
      "outputs": [],
      "source": [
        "g_new=ge[l_gid]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "g_new.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SoFJXDava5Rx",
        "outputId": "8afe3d04-4256-40cd-8698-8eb37291a804"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(11768, 115)"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4VRbAD25eWgU",
        "outputId": "44444257-daa3-45da-8a6f-f1bbe80ed89f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['TARGET-15-SJMPAL040026-09A', 'TARGET-15-SJMPAL040038-09B', 'TARGET-15-SJMPAL042799-09A', 'TARGET-15-SJMPAL043513-04B', 'TARGET-15-SJMPAL040036-03B', 'TARGET-15-SJMPAL044949-09A', 'TARGET-15-SJMPAL040035-03A', 'TARGET-15-SJMPAL043774-09B', 'TARGET-15-SJMPAL012421-09B', 'TARGET-20-SJAML045735-09A', 'TARGET-15-SJMPAL043773-40A', 'TARGET-15-SJMPAL042797-09A', 'TARGET-15-SJMPAL042946-09B', 'TARGET-15-SJMPAL016342-09A', 'TARGET-15-SJMPAL042794-09A', 'TARGET-15-SJMPAL043770-09B', 'TARGET-15-SJMPAL012422-09A', 'TARGET-15-SJMPAL042793-09B', 'TARGET-15-SJMPAL016344-09A', 'TARGET-20-SJAML045734-09A', 'TARGET-15-SJMPAL040037-09B', 'TARGET-15-SJMPAL040459-09B', 'TARGET-15-SJMPAL016448-09A', 'TARGET-15-SJMPAL042943-09A', 'TARGET-15-SJMPAL040025-09B', 'TARGET-15-SJMPAL042801-09A', 'TARGET-15-SJMPAL041120-09B', 'TARGET-15-SJMPAL016342-09B', 'TARGET-15-SJMPAL043769-03B', 'TARGET-15-SJMPAL011911-03A', 'TARGET-15-SJMPAL046466-09A', 'TARGET-15-SJMPAL042791-09B', 'TARGET-15-SJMPAL040034-09A', 'TARGET-15-PAUFIB-09B', 'TARGET-15-SJMPAL046468-09A', 'TARGET-15-SJMPAL040031-09A', 'TARGET-15-SJMPAL042793-09A', 'TARGET-20-SJAML040268-09A', 'TARGET-15-SJMPAL043768-09B', 'TARGET-15-PAVFTF-09B', 'TARGET-15-SJMPAL012425-09A', 'TARGET-15-SJMPAL046467-09A', 'TARGET-15-SJMPAL019076-04B', 'TARGET-20-SJAML003320-09A', 'TARGET-15-SJMPAL043510-09A', 'TARGET-15-PAREAT-09B', 'TARGET-15-SJMPAL046470-09A', 'TARGET-15-SJMPAL040459-09A', 'TARGET-20-SJAML003322-09A', 'TARGET-15-SJMPAL040028-04B', 'TARGET-15-SJMPAL043507-04B', 'TARGET-15-SJMPAL042794-09B', 'TARGET-15-SJMPAL041118-09A', 'TARGET-15-SJMPAL044953-09A', 'TARGET-15-SJMPAL040033-09A', 'TARGET-15-SJMPAL040030-09A', 'TARGET-15-SJMPAL041117-09A', 'TARGET-15-SJMPAL043772-04B', 'TARGET-15-SJMPAL017975-03A', 'TARGET-15-SJMPAL043506-04B', 'TARGET-15-SJMPAL016447-09A', 'TARGET-20-SJAML045739-09A', 'TARGET-20-SJAML045742-09A', 'TARGET-15-SJMPAL041119-09B', 'TARGET-15-SJMPAL011914-09A', 'TARGET-15-SJMPAL043767-09B', 'TARGET-15-SJMPAL011912-09A', 'TARGET-15-SJMPAL011914-09B', 'TARGET-15-SJMPAL044948-09A', 'TARGET-15-SJMPAL044950-09A', 'TARGET-15-SJMPAL040038-09A', 'TARGET-15-SJMPAL012418-09A', 'TARGET-15-SJMPAL040039-09B', 'TARGET-20-SJAML045736-09A', 'TARGET-15-SJMPAL040036-03A', 'TARGET-15-SJMPAL043508-09B', 'TARGET-15-SJMPAL011913-09A', 'TARGET-15-SJMPAL042946-09A', 'TARGET-15-SJMPAL042787-09A', 'TARGET-15-SJMPAL017975-03B', 'TARGET-20-SJAML045738-09A', 'TARGET-15-SJMPAL041119-09A', 'TARGET-15-SJMPAL040039-09A', 'TARGET-15-SJMPAL022667-09A', 'TARGET-15-SJMPAL017981-03A', 'TARGET-15-SJMPAL042946-04B', 'TARGET-15-SJMPAL042796-09A', 'TARGET-15-SJMPAL043509-04A', 'TARGET-20-SJAML007112-09A', 'TARGET-15-SJMPAL043773-03B', 'TARGET-15-SJMPAL046469-09A', 'TARGET-15-SJMPAL012419-09B', 'TARGET-15-SJMPAL003414-04A', 'TARGET-15-SJMPAL012419-09A', 'TARGET-15-SJMPAL042798-09A', 'TARGET-15-SJMPAL043771-09B', 'TARGET-15-SJMPAL046471-09A', 'TARGET-15-SJMPAL005001-04A', 'TARGET-15-SJMPAL043514-09A', 'TARGET-15-SJMPAL011915-09A', 'TARGET-15-SJMPAL040028-04A', 'TARGET-15-SJMPAL043775-09B', 'TARGET-15-SJMPAL042791-09A', 'TARGET-15-SJMPAL017978-09A', 'TARGET-15-SJMPAL040037-09A', 'TARGET-20-SJAML045737-09A', 'TARGET-15-SJMPAL043505-09B', 'TARGET-15-SJMPAL016343-09A', 'TARGET-20-SJAML007113-09A', 'TARGET-15-SJMPAL004013-04A', 'TARGET-15-SJMPAL046472-09A', 'TARGET-20-SJAML045741-09A', 'TARGET-15-SJMPAL043512-09B', 'TARGET-15-SJMPAL040024-09A', 'TARGET-15-SJMPAL042787-09B', 'TARGET-15-SJMPAL043511-09B', 'TARGET-15-PARWPU-09A', 'TARGET-15-SJMPAL016340-09A', 'TARGET-15-SJMPAL041117-09B', 'TARGET-15-SJMPAL017973-09A', 'TARGET-15-SJMPAL041122-09A', 'TARGET-15-SJMPAL042801-09B', 'TARGET-15-SJMPAL012417-09A', 'TARGET-15-PARWPU-09B', 'TARGET-15-SJMPAL040025-09A', 'TARGET-15-SJMPAL017977-09A', 'TARGET-15-SJMPAL042799-09B', 'TARGET-15-SJMPAL042798-09B', 'TARGET-15-SJMPAL041120-09A', 'TARGET-15-PASZVW-09B', 'TARGET-20-SJAML016570-09A', 'TARGET-20-SJAML045740-09A', 'TARGET-15-SJMPAL042792-09A', 'TARGET-15-SJMPAL040027-09A', 'TARGET-15-SJMPAL012420-09A', 'TARGET-20-PASTUH-04A', 'TARGET-20-PARYFN-04A', 'TARGET-20-PARIMT-03A', 'TARGET-20-PANPLS-03A', 'TARGET-20-PARJCR-09A', 'TARGET-20-PASGWH-09A', 'TARGET-20-PASBHI-09A', 'TARGET-20-PARBFJ-09A', 'TARGET-20-PASMHY-03A', 'TARGET-20-PATIAK-04A', 'TARGET-20-PARXNG-09A', 'TARGET-20-PASVVS-09A', 'TARGET-20-PANUTB-09A', 'TARGET-20-PAPAWN-09A', 'TARGET-20-PARXBT-09A', 'TARGET-20-PASWPT-09A', 'TARGET-20-PARAJX-09A', 'TARGET-20-PARYFN-03A', 'TARGET-20-PARHVK-09A', 'TARGET-20-PANKFZ-09A', 'TARGET-20-PARUNX-09A', 'TARGET-20-PAPVZK-09A', 'TARGET-20-PANLIR-09A', 'TARGET-20-PATDNN-09A', 'TARGET-20-PARZUU-09A', 'TARGET-20-PANNHB-09A', 'TARGET-20-PANVGP-03A', 'TARGET-20-PAMYAS-09A', 'TARGET-20-PADYIR-04A', 'TARGET-20-PAPVCN-09A', 'TARGET-20-PARBRA-09A', 'TARGET-20-PARVAI-03A', 'TARGET-20-PANUUA-09A', 'TARGET-20-PARPDS-09A', 'TARGET-20-PAEFGT-03A', 'TARGET-20-PARWDZ-09A', 'TARGET-20-PASCGR-03A', 'TARGET-20-PATJHJ-09A', 'TARGET-20-PADYIR-09A', 'TARGET-20-PASHYZ-04A', 'TARGET-20-PASPTM-09A', 'TARGET-20-PASTUH-03A', 'TARGET-20-PARJYP-03A', 'TARGET-20-PANYSN-03A', 'TARGET-20-PAPVDV-03A', 'TARGET-20-PASJGZ-04A', 'TARGET-20-PASMYS-04A', 'TARGET-20-PANKKE-09A', 'TARGET-20-PARBIU-04A', 'TARGET-20-PANPTM-09A', 'TARGET-20-PANYNR-03A', 'TARGET-20-PARYVW-04A', 'TARGET-20-PAEDKB-04A', 'TARGET-20-PANKNB-09A', 'TARGET-20-PARCCH-03A', 'TARGET-20-PAKTCX-04A', 'TARGET-20-PARANT-09A', 'TARGET-20-PASVYA-09A', 'TARGET-20-PASVYA-04A', 'TARGET-20-PASBBE-04A', 'TARGET-20-PARXMP-09A', 'TARGET-20-PARCUK-09A', 'TARGET-20-PASBPK-09A', 'TARGET-20-PASPGA-09A', 'TARGET-20-PAECCE-09A', 'TARGET-20-PASFEW-09A', 'TARGET-20-PASWLN-09A', 'TARGET-20-PARUUB-09A', 'TARGET-20-PASWPD-09A', 'TARGET-20-PASXNR-04A', 'TARGET-20-PAEFGT-04A', 'TARGET-20-PARDDY-09A', 'TARGET-20-PAPXRJ-09A', 'TARGET-20-PANLXM-09A', 'TARGET-20-PASIBG-09A', 'TARGET-20-PATELT-03A', 'TARGET-20-PANLJN-09A', 'TARGET-20-PASYJI-04A', 'TARGET-20-PARMZF-09A', 'TARGET-20-PARSHM-03A', 'TARGET-20-PANLKB-09A', 'TARGET-20-PAMYAS-04A', 'TARGET-20-PAKTCX-09A', 'TARGET-20-PASPLU-04A', 'TARGET-20-PASHYZ-09A', 'TARGET-20-PALGKX-04A', 'TARGET-20-PAPBEJ-09A', 'TARGET-20-PATDNN-04A', 'TARGET-20-PANDER-09A', 'TARGET-20-PARTAL-09A', 'TARGET-20-PARBIU-09A', 'TARGET-20-PANAEV-09A', 'TARGET-20-PARSAN-03A', 'TARGET-20-PANINI-09A', 'TARGET-20-PARUWX-09A', 'TARGET-20-PAEERJ-09A', 'TARGET-20-PARYGA-09A', 'TARGET-20-PANLLX-09A', 'TARGET-20-PASSSI-09A', 'TARGET-20-PARPWL-09A', 'TARGET-20-PANHYK-09A', 'TARGET-20-PANFMG-09A', 'TARGET-20-PANBZH-09A', 'TARGET-20-PARUBT-40A', 'TARGET-20-PASHBI-09A', 'TARGET-20-PAKIYW-09A', 'TARGET-20-PASLSD-03A', 'TARGET-20-PARCZL-04A', 'TARGET-20-PAEIKD-09A', 'TARGET-20-PARGVC-03A', 'TARGET-20-PASPLU-09A', 'TARGET-20-PAKERZ-09A', 'TARGET-20-PASINN-04A', 'TARGET-20-PARLVL-04A', 'TARGET-20-PARASV-03A', 'TARGET-20-PARTAL-04A', 'TARGET-20-PARKCX-09A', 'TARGET-20-PANDIX-09A', 'TARGET-20-PANVGE-09A', 'TARGET-20-PATIAK-09A', 'TARGET-20-PASGGK-03A', 'TARGET-20-PASVVS-04A', 'TARGET-20-PANLIZ-04A', 'TARGET-20-PANSJB-09A', 'TARGET-20-PATDHA-09A', 'TARGET-20-PANSBH-09A', 'TARGET-20-PARUDL-03A', 'TARGET-20-PANGDN-09A', 'TARGET-20-PAMYGX-09A', 'TARGET-20-PASMGW-09A', 'TARGET-20-PASXYG-09A', 'TARGET-20-PARDMG-09A', 'TARGET-20-PANGCM-03A', 'TARGET-20-PAEERJ-04A', 'TARGET-20-PASWAT-09A', 'TARGET-20-PARCZL-09A', 'TARGET-20-PAKSMZ-03A', 'TARGET-20-PASGMZ-09A', 'TARGET-20-PAKLPD-09A', 'TARGET-20-PAPXWI-09A', 'TARGET-20-PARYVW-09A', 'TARGET-20-PASCRZ-04A', 'TARGET-20-PANZKA-09A', 'TARGET-20-PASTTW-09A', 'TARGET-20-PARENB-09A', 'TARGET-20-PARFAL-09A', 'TARGET-20-PANTPW-09A', 'TARGET-20-PASGWH-04A', 'TARGET-20-PANPKN-09A', 'TARGET-20-PAKIWK-04A', 'TARGET-20-PARZWH-09A', 'TARGET-20-PAPWIU-09A', 'TARGET-20-PAEIKD-04A', 'TARGET-20-PAPWYK-09A', 'TARGET-20-PAPWHS-09A', 'TARGET-20-PARFAL-04A', 'TARGET-20-PANTNA-09A', 'TARGET-20-PAKIWK-09A', 'TARGET-20-PARDDY-04A', 'TARGET-20-PADZCG-09A', 'TARGET-20-PAPXRJ-04A', 'TARGET-20-PASZLJ-09A', 'TARGET-20-PARUTH-09A', 'TARGET-20-PASWAJ-09A', 'TARGET-20-PARUNX-04A', 'TARGET-20-PANGTF-09A', 'TARGET-20-PASGZS-04A', 'TARGET-20-PASYJI-09A', 'TARGET-20-PAEFGR-09A', 'TARGET-20-PASPKE-09A', 'TARGET-20-PASVYL-09A', 'TARGET-20-PAKVGI-09A', 'TARGET-20-PATJHJ-40A', 'TARGET-20-PARIHK-03A', 'TARGET-20-PAEAKL-09A', 'TARGET-20-PASJTM-09A', 'TARGET-20-PAKERZ-04A', 'TARGET-20-PAMVKZ-09A', 'TARGET-20-PALGKX-09A', 'TARGET-20-PASWAJ-04A', 'TARGET-20-PARIZR-03A', 'TARGET-20-PANLIZ-09A', 'TARGET-20-PADZCG-04A', 'TARGET-20-PANGJY-09A', 'TARGET-20-PASCFW-09A', 'TARGET-20-PANWHP-09A', 'TARGET-20-PABLDZ-04A', 'TARGET-51-PALFYG-01A', 'TARGET-51-PAEALX-01A', 'TARGET-51-PAJMNM-01A', 'TARGET-51-PALLXV-01A', 'TARGET-51-PALEIR-01A', 'TARGET-51-PAJMFS-01A', 'TARGET-51-PALKEI-01A', 'TARGET-51-PALFEF-01A', 'TARGET-51-PAJNCV-01A', 'TARGET-51-PAJPFB-01A', 'TARGET-51-PAKWMM-01A', 'TARGET-51-PAJLIV-01A', 'TARGET-51-PAJLWU-01A', 'TARGET-30-PAPVFD-01A', 'TARGET-30-PARACS-01A', 'TARGET-30-PAPHPE-01A', 'TARGET-30-PAPTAN-01A', 'TARGET-30-PAPZYP-01A', 'TARGET-30-PANLET-01A', 'TARGET-30-PATAYJ-01A', 'TARGET-30-PARDCK-01A', 'TARGET-30-PATDXG-01A', 'TARGET-30-PAIFXV-01A', 'TARGET-30-PATYIL-02A', 'TARGET-30-PARBAJ-02A', 'TARGET-30-PAMZMG-01A', 'TARGET-30-PASGAP-01A', 'TARGET-30-PASJZC-01A', 'TARGET-30-PASCFC-01A', 'TARGET-30-PALKUC-01A', 'TARGET-30-PARFWB-01A', 'TARGET-30-PAPBGH-01A', 'TARGET-30-PAPCTS-01A', 'TARGET-30-PAKZRH-01A', 'TARGET-30-PASXRJ-01A', 'TARGET-30-PASGAP-02A', 'TARGET-30-PASTCN-01A', 'TARGET-30-PAPVXS-01A', 'TARGET-30-PAKYZS-01A', 'TARGET-30-PAPKWN-01A', 'TARGET-30-PAPEFE-01A', 'TARGET-30-PAUDDK-02A', 'TARGET-30-PANRRW-01A', 'TARGET-30-PANSBN-01A', 'TARGET-30-PATDWN-01A', 'TARGET-30-PARJVP-01A', 'TARGET-30-PAISNS-01A', 'TARGET-30-PAPUNH-01A', 'TARGET-30-PAPTLV-01A', 'TARGET-30-PANXJL-01A', 'TARGET-30-PAMMXF-01A', 'TARGET-30-PAUDDK-01A', 'TARGET-30-PASVRU-01A', 'TARGET-30-PALUYS-01A', 'TARGET-30-PATFCY-01A', 'TARGET-30-PASFIC-01A', 'TARGET-30-PASXGP-01A', 'TARGET-30-PASZKE-01A', 'TARGET-30-PASPER-01A', 'TARGET-30-PASCTR-01A', 'TARGET-30-PANZPV-01A', 'TARGET-30-PARSBI-01A', 'TARGET-30-PATGJU-01A', 'TARGET-30-PATYIL-01A', 'TARGET-30-PASUYG-01A', 'TARGET-30-PATBMM-01A', 'TARGET-30-PAPZYZ-01A', 'TARGET-30-PARBAJ-01A', 'TARGET-30-PALCBW-01A', 'TARGET-30-PASWIJ-01A', 'TARGET-30-PARACM-01A', 'TARGET-30-PARHAM-02A', 'TARGET-30-PANBSP-01A', 'TARGET-30-PASFGG-01A', 'TARGET-30-PAPICY-01A', 'TARGET-30-PASXHE-01A', 'TARGET-30-PARNNC-01A', 'TARGET-30-PASNML-01A', 'TARGET-30-PANWRR-01A', 'TARGET-30-PALETP-01A', 'TARGET-30-PALNVP-01A', 'TARGET-30-PATHKB-01A', 'TARGET-30-PAMVRA-01A', 'TARGET-30-PALEVG-01A', 'TARGET-30-PATDXC-01A', 'TARGET-30-PASMNT-01A', 'TARGET-30-PASZPI-01A', 'TARGET-30-PASSWW-01A', 'TARGET-30-PALTEG-01A', 'TARGET-30-PAPTDH-01A', 'TARGET-30-PANBJH-01A', 'TARGET-30-PANYGR-01A', 'TARGET-30-PASHFA-01A', 'TARGET-30-PATHVK-01A', 'TARGET-30-PANRVJ-01A', 'TARGET-30-PAPBZI-01A', 'TARGET-30-PALZZV-01A', 'TARGET-30-PASMDM-01A', 'TARGET-30-PARAMT-01A', 'TARGET-30-PARZIP-01A', 'TARGET-30-PAPKXS-01A', 'TARGET-30-PAMNLH-01A', 'TARGET-30-PATINJ-01A', 'TARGET-30-PASNPG-01A', 'TARGET-30-PASSRN-01A', 'TARGET-30-PAMYCE-01A', 'TARGET-30-PALVKK-01A', 'TARGET-30-PAMEZH-01A', 'TARGET-30-PARZCJ-01A', 'TARGET-30-PARHAM-01A', 'TARGET-30-PATFXV-01A', 'TARGET-30-PARFRE-01A', 'TARGET-30-PALBFW-01A', 'TARGET-30-PAPTCR-01A', 'TARGET-30-PASWFB-01A', 'TARGET-30-PANZRV-01A', 'TARGET-30-PARDIW-01A', 'TARGET-30-PAPVEB-04A', 'TARGET-30-PASSRS-01A', 'TARGET-30-PAIVHE-01A', 'TARGET-30-PATEKG-01A', 'TARGET-30-PALIIN-01A', 'TARGET-30-PANGXK-01A', 'TARGET-30-PASMJG-01A', 'TARGET-30-PATCFL-01A', 'TARGET-30-PATGLU-01A', 'TARGET-30-PASNPG-02A', 'TARGET-30-PARKGJ-01A', 'TARGET-30-PASWYR-01A', 'TARGET-30-PASNEF-01A', 'TARGET-30-PASUCB-01A', 'TARGET-30-PAPLSD-01A', 'TARGET-30-PANBMJ-01A', 'TARGET-30-PARGKK-01A', 'TARGET-30-PASWVY-01A', 'TARGET-30-PATEPF-01A', 'TARGET-30-PATNKP-02A', 'TARGET-30-PAITCI-01A', 'TARGET-30-PASNZU-01A', 'TARGET-30-PAMZGT-01A', 'TARGET-30-PASPBZ-01A', 'TARGET-30-PANNMS-01A', 'TARGET-30-PASEGA-01A', 'TARGET-30-PASXRG-01A', 'TARGET-30-PALWVJ-01A', 'TARGET-30-PARVLK-01A', 'TARGET-30-PASRFS-01A', 'TARGET-30-PAIPGU-01A', 'TARGET-30-PAPUEB-01A', 'TARGET-30-PASXIE-01A', 'TARGET-30-PANUIF-01A', 'TARGET-30-PARYNK-01A', 'TARGET-30-PATESI-01A', 'TARGET-30-PASTKC-01A', 'TARGET-30-PARBGP-01A', 'TARGET-30-PALXTB-01A', 'TARGET-30-PANJLH-01A', 'TARGET-30-PAPUWY-01A', 'TARGET-30-PASGUT-01A', 'TARGET-30-PARZHA-01A', 'TARGET-30-PAPVRN-01A', 'TARGET-30-PANZVU-01A', 'TARGET-30-PAPBJE-01A', 'TARGET-40-PASUUH-01A', 'TARGET-40-PAUTWB-01A', 'TARGET-40-PAKUZU-01A', 'TARGET-40-0A4I0S-01A', 'TARGET-40-PARJXU-01A', 'TARGET-40-PAPWWC-01A', 'TARGET-40-PAUUML-01A', 'TARGET-40-PAMHLF-01A', 'TARGET-40-PAUBIT-01A', 'TARGET-40-PASFCV-01A', 'TARGET-40-PATMPU-01A', 'TARGET-40-0A4I4O-01A', 'TARGET-40-0A4I48-01A', 'TARGET-40-PASEFS-01A', 'TARGET-40-PATUXZ-01A', 'TARGET-40-PAMHYN-01A', 'TARGET-40-PASEBY-01A', 'TARGET-40-PANMIG-01A', 'TARGET-40-PAKFVX-01A', 'TARGET-40-PASNZV-01A', 'TARGET-40-0A4I4M-01A', 'TARGET-40-PAMYYJ-01A', 'TARGET-40-0A4I0Q-01A', 'TARGET-40-0A4I42-01A', 'TARGET-40-PASYUK-01A', 'TARGET-40-PALECC-01A', 'TARGET-40-PAMLKS-01A', 'TARGET-40-PANSEN-01A', 'TARGET-40-PAPIJR-01A', 'TARGET-40-PALHRL-01A', 'TARGET-40-PANZHX-01A', 'TARGET-40-PALKDP-01A', 'TARGET-40-0A4I65-01A', 'TARGET-40-0A4I6O-01A', 'TARGET-40-PALFYN-01A', 'TARGET-40-PATPBS-01A', 'TARGET-40-PAPXGT-01A', 'TARGET-40-0A4I4E-01A', 'TARGET-40-0A4HLD-01A', 'TARGET-40-PAUYTT-01A', 'TARGET-40-0A4I0W-01A', 'TARGET-40-PARFTG-01A', 'TARGET-40-0A4HX8-01A', 'TARGET-40-PAMRHD-01A', 'TARGET-40-PATMXR-01A', 'TARGET-40-PAPKWD-01A', 'TARGET-40-PAPNVD-01A', 'TARGET-40-PAKXLD-01A', 'TARGET-40-PAPFLB-01A', 'TARGET-40-PARBGW-01A', 'TARGET-40-PAMEKS-01A', 'TARGET-40-PAVDTY-01A', 'TARGET-40-PANGPE-01A', 'TARGET-40-PAMJXS-01A', 'TARGET-40-PAKZZK-01A', 'TARGET-40-PALWWX-01A', 'TARGET-40-PASKZZ-01A', 'TARGET-40-PAVALD-01A', 'TARGET-40-PATEEM-01A', 'TARGET-40-PAVECB-01A', 'TARGET-40-PALKGN-01A', 'TARGET-40-PASRNE-01A', 'TARGET-40-PARGTM-01A', 'TARGET-40-PAUVUL-01A', 'TARGET-40-PANGRW-01A', 'TARGET-40-PAVCLP-01A', 'TARGET-40-PATAWV-01A', 'TARGET-40-PARKAF-01A', 'TARGET-40-PANXSC-01A', 'TARGET-40-0A4HMC-01A', 'TARGET-40-PAUXPZ-01A', 'TARGET-40-PATJVI-01A', 'TARGET-40-PAUTYB-01A', 'TARGET-40-PALZGU-01A', 'TARGET-40-PANZZJ-01A', 'TARGET-40-PATKSS-01A', 'TARGET-40-PATMIF-01A', 'TARGET-40-PANPUM-01A', 'TARGET-40-PARDAX-01A', 'TARGET-40-PASSLM-01A', 'TARGET-40-PAMTCM-01A', 'TARGET-40-0A4HY5-01A', 'TARGET-40-0A4HXS-01A', 'TARGET-40-0A4I8U-01A', 'TARGET-40-0A4I9K-01A', 'TARGET-40-0A4I3S-01A', 'TARGET-40-PANVJJ-01A', 'TARGET-40-0A4I5B-01A', 'TARGET-52-PAUDPV-11A', 'TARGET-52-PARZBI-11A', 'TARGET-52-PASDLA-11A', 'TARGET-52-PARPFY-11A', 'TARGET-52-PARRCL-11A', 'TARGET-50-PAKULH-01A', 'TARGET-50-PAKKSE-01A', 'TARGET-50-PAJLLF-01A', 'TARGET-50-PAKNTW-01A', 'TARGET-50-PALLFB-01A', 'TARGET-50-CAAAAL-01A', 'TARGET-50-PALGVY-01A', 'TARGET-50-PAJNCC-01A', 'TARGET-50-PAKNRX-01A', 'TARGET-50-PAJNZK-01A', 'TARGET-50-PAJNSL-01A', 'TARGET-50-CAAAAS-01A', 'TARGET-50-PAKMUB-01A', 'TARGET-50-PAJMLZ-01A', 'TARGET-50-PAJLNJ-01A', 'TARGET-50-PAKKNS-01A', 'TARGET-50-PAKMSV-01A', 'TARGET-50-PAJLKC-01A', 'TARGET-50-CAAAAC-01A', 'TARGET-50-PALFME-02A', 'TARGET-50-PALJIP-02A', 'TARGET-50-PAJMJT-01A', 'TARGET-50-PAJLKR-01A', 'TARGET-50-PAKSDG-01A', 'TARGET-50-PAKZHF-01A', 'TARGET-50-CAAAAJ-01A', 'TARGET-50-PAJMVU-01A', 'TARGET-50-PAKNAL-01A', 'TARGET-50-PALKCW-11A', 'TARGET-50-CAAAAO-01A', 'TARGET-50-PAJLUJ-06A', 'TARGET-50-PAJNDU-01A', 'TARGET-50-PALGAZ-01A', 'TARGET-50-CAAAAM-01A', 'TARGET-50-PAJMFU-01A', 'TARGET-50-PAJNAA-01A', 'TARGET-50-PAJMMY-01A', 'TARGET-50-PAJNRL-01A', 'TARGET-50-PAJNZS-01A', 'TARGET-50-PAEBXA-01A', 'TARGET-50-PAJNNC-01A', 'TARGET-50-PAJMRL-01A', 'TARGET-50-PAJNLT-01A', 'TARGET-50-PADZUB-01A', 'TARGET-50-PAKXWB-01A', 'TARGET-50-PAJNZI-01A', 'TARGET-50-PAJMSE-01A', 'TARGET-50-PALERC-01A', 'TARGET-50-PAJPDC-02A', 'TARGET-50-PAJLTH-01A', 'TARGET-50-PAKYFC-01A', 'TARGET-50-PALGLU-01A', 'TARGET-50-PAKRZW-01A', 'TARGET-50-PAJNUS-01A', 'TARGET-50-PAJNTJ-01A', 'TARGET-50-PAJNVX-01A', 'TARGET-50-PAJNAV-01A', 'TARGET-50-PAKFYV-01A', 'TARGET-50-PAKECR-01A', 'TARGET-50-PAJLTI-01A', 'TARGET-50-CAAAAR-01A', 'TARGET-50-PAJMEN-01A', 'TARGET-50-PAJLSP-01A', 'TARGET-50-PAKRVH-01A', 'TARGET-50-PAKRCC-01A', 'TARGET-50-PAKYLT-01A', 'TARGET-50-PAJNEC-01A', 'TARGET-50-PALFME-01A', 'TARGET-50-PAKNXS-01A', 'TARGET-50-PAJPHA-11A', 'TARGET-50-PAKUIT-01A', 'TARGET-50-PALKCW-01A', 'TARGET-50-PALEZT-01A', 'TARGET-50-PAKWPM-01A', 'TARGET-50-PAJMXF-01A', 'TARGET-50-PAKGED-01A', 'TARGET-50-PAJNJJ-01A', 'TARGET-50-PAJMKI-01A', 'TARGET-50-PAEAFB-01A', 'TARGET-50-PAJPAR-01A', 'TARGET-50-PAKZER-01A', 'TARGET-50-PAKVET-01A', 'TARGET-50-PAJLWT-01A', 'TARGET-50-PAJMFY-01A', 'TARGET-50-PAJLPX-01A', 'TARGET-50-PAJMIZ-01A', 'TARGET-50-PAKXXF-01A', 'TARGET-50-PAJNCZ-01A', 'TARGET-50-PAJMEL-01A', 'TARGET-50-PAJNGH-01A', 'TARGET-50-PAKPDF-01A', 'TARGET-50-PAJNVE-01A', 'TARGET-50-PAKGZX-01A', 'TARGET-50-PAJMUF-01A', 'TARGET-50-PAJNRL-11A', 'TARGET-50-CAAAAH-01A', 'TARGET-50-PALKRS-01A', 'TARGET-50-PALDWP-01A', 'TARGET-50-PAKJGM-01A', 'TARGET-50-CAAAAR-11A', 'TARGET-50-PAJPDC-01A', 'TARGET-50-PAJNCJ-01A', 'TARGET-50-PAKFME-01A', 'TARGET-50-PALJIP-01A', 'TARGET-50-PAJPGY-01A', 'TARGET-50-PAJMVC-01A', 'TARGET-50-PALDTE-01A', 'TARGET-50-PAJPDN-01A', 'TARGET-50-PAJPHA-01A', 'TARGET-50-PAJNRH-01A', 'TARGET-50-PAJLIP-01A', 'TARGET-50-PADXAY-01A', 'TARGET-50-PAKZFK-01A', 'TARGET-50-PAJPCM-01A', 'TARGET-50-PAJNBN-01A', 'TARGET-50-PAJNGH-02A', 'TARGET-50-PAKGMU-01A', 'TARGET-50-PAJNUP-01A', 'TARGET-50-PAJPEW-01A', 'TARGET-50-PAJMLI-01A', 'TARGET-50-PAJMEP-01A', 'TARGET-50-PAJNYT-01A', 'TARGET-50-PAJMKJ-01A', 'TARGET-50-CAAAAQ-11A', 'TARGET-50-PAKSCC-01A', 'TARGET-50-PAJNSL-11A', 'TARGET-50-PAJPAU-01A', 'TARGET-50-PAJNZU-01A', 'TARGET-50-PAJNNR-01A', 'TARGET-50-PAJNTJ-02A', 'TARGET-50-PAECJB-01A', 'TARGET-50-PALFRD-01A']\n"
          ]
        }
      ],
      "source": [
        "drop_in=[]\n",
        "for i in g_new.index:\n",
        "  if i.split(\"-\")[0]=='TARGET':\n",
        "    drop_in.append(i)\n",
        "print(drop_in)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "estVinlya2Zg"
      },
      "outputs": [],
      "source": [
        "label_dict['nan']=\"RS\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9z3UphArXPRw",
        "outputId": "d3eff9d6-a462-468e-ec52-5357e2a9a291"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(11058, 115)\n"
          ]
        }
      ],
      "source": [
        "g_df = ge[l_gid]\n",
        "g_df=g_df.dropna(axis='columns')\n",
        "g_df = g_df.drop(drop_in)\n",
        "print(g_df.shape)\n",
        "sample_type =[]\n",
        "for i in g_df.index:\n",
        "  sample_type.append(label_dict[i])\n",
        "label =pd.DataFrame(sample_type).to_numpy()\n",
        "g_df=g_df.to_numpy()"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "M-ot7r17e5I4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sML8TfewbFZp",
        "outputId": "88ba41ad-7e73-470f-aaa5-51c32e67ed7e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(7740, 115) (3318, 115)\n"
          ]
        }
      ],
      "source": [
        "X_train, X_test, y_tr, y_tst = train_test_split(g_df,label,test_size = 0.3,random_state = 42)\n",
        "print(X_train.shape, X_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "p=0\n",
        "n=0\n",
        "for i,y in enumerate(y_tr):\n",
        "  if y=='RS':\n",
        "    y_tr[i]=1\n",
        "    p+=1\n",
        "  else:\n",
        "    y_tr[i]=0\n",
        "    n+=1\n",
        "print(p,n)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lMnxdfllmbR-",
        "outputId": "f6f186d0-1364-4379-8ab1-221dc0b893df"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7238 502\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_train = y_tr.flatten()\n",
        "\n",
        "print(y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e-RR019hmkGX",
        "outputId": "8d1d05a6-fa65-46fb-ced3-cbff167d2b42"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1 1 1 ... 1 1 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "p=0\n",
        "n=0\n",
        "for i,y in enumerate(y_tst):\n",
        "  if y=='RS':\n",
        "    y_tst[i]=1\n",
        "    p+=1\n",
        "  else:\n",
        "    y_tst[i]=0\n",
        "    n+=1\n",
        "print(p,n)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nEeDsLoTmkQg",
        "outputId": "fe0781d3-ea4e-4835-efea-eb9d21e2cc82"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3090 228\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_test = y_tst.flatten()\n",
        "\n",
        "print(y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "80217658-c7a6-4147-c548-ec73cb5dfb09",
        "id": "IoPMdz5wmkQh"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1 1 1 ... 1 1 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#import numpy as np\n",
        "#from imblearn.over_sampling import RandomOverSampler\n",
        "#ros = RandomOverSampler(random_state=42)\n",
        "\n",
        "# Perform random oversampling\n",
        "#X_train, y_train = ros.fit_resample(X_tr, y_tr)\n",
        "\n",
        "#print(\"Original dataset shape:\", X_tr.shape)\n",
        "#print(\"Resampled dataset shape:\", X_train.shape)\n",
        "\n",
        "#print(\"Original class distribution:\", np.bincount(y_tr.flatten))\n",
        "#print(\"Resampled class distribution:\", np.bincount(y_train))"
      ],
      "metadata": {
        "id": "yC6iI0L3ii-T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tf9_Rtz9dCDg"
      },
      "outputs": [],
      "source": [
        "#from imblearn.over_sampling import SMOTE\n",
        "#print(\"Before SMOTE - Tumor samples:\", sum(y_tr == \"RS\"))\n",
        "#print(\"Before SMOTE - Normal samples:\", sum(y_tr == \"C\"))\n",
        "#print(\"Before SMOTE - Tumor samples:\", sum(y_tst == \"RS\"))\n",
        "#print(\"Before SMOTE - Normal samples:\", sum(y_tst == \"C\"))\n",
        "#smote = SMOTE(random_state=42)\n",
        "#X_train, y_train = smote.fit_resample(X_tr, y_tr)\n",
        "#print(\"After SMOTE - Tumor samples:\", sum(y_train == \"RS\"))\n",
        "#print(\"After SMOTE - Normal samples:\", sum(y_train == \"C\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9Iy5z8tnb7tq"
      },
      "outputs": [],
      "source": [
        "#for i,y in enumerate(y_train):\n",
        " # if y=='RS':\n",
        "  #  y_train[i]=1\n",
        "  #else:\n",
        "    #y_train[i]=0"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#for i,y in enumerate(y_tst):\n",
        " # if y=='RS':\n",
        "  #  y_tst[i]=1\n",
        "  #else:\n",
        "   # y_tst[i]=0"
      ],
      "metadata": {
        "id": "uPGxYlGPNnL4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#y_test = y_tst.flatten()\n",
        "\n",
        "#print(y_test)"
      ],
      "metadata": {
        "id": "0FWSWhZzaAum"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AXZpNeCfbtip",
        "outputId": "0be0d0fc-08e6-4964-918b-9966a45aa690"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n"
          ]
        }
      ],
      "source": [
        "print(type(X_train))\n",
        "print(type(y_train))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = X_train.astype('float32')\n",
        "X_test = X_test.astype('float32')\n",
        "y_train = y_train.astype('float32')\n",
        "y_test = y_test.astype('float32')"
      ],
      "metadata": {
        "id": "dWf-X43Bi_34"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_train = y_train.astype(int)"
      ],
      "metadata": {
        "id": "ufOOiAOlQM4M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "\n",
        "# Define the CSV file path\n",
        "results_file = '/content/drive/MyDrive/phd/pancan/Revised5/model_results.csv'"
      ],
      "metadata": {
        "id": "t001GYashNMR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "np.random.seed(42)\n",
        "import random\n",
        "random.seed(42)\n",
        "tf.config.experimental.enable_op_determinism()\n",
        "import os\n",
        "os.environ['PYTHONHASHSEED'] = '42'\n",
        "os.environ['TF_DETERMINISTIC_OPS'] = '1'\n",
        "os.environ['CUDA_VISIBLE_DEVICES'] = '0'"
      ],
      "metadata": {
        "id": "_hxot7tPaene"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "tf.random.set_seed(42)\n",
        "import tensorflow as tf\n",
        "import keras_tuner as kt\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, roc_curve, auc, confusion_matrix, f1_score\n",
        "from imblearn.over_sampling import SMOTE\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import precision_recall_curve\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "# Define the model builder\n",
        "def model_builder1(hp):\n",
        "    model = tf.keras.Sequential()\n",
        "    model.add(tf.keras.layers.Flatten(input_shape=X_train[0].shape))\n",
        "\n",
        "    hp_activation = hp.Choice('activation', values=['relu', 'tanh'])\n",
        "    hp_layer_1 = hp.Int('layer_1', min_value=1, max_value=1000, step=100)\n",
        "    #model.add(keras.layers.Dropout(0.2))\n",
        "    hp_layer_2 = hp.Int('layer_2', min_value=1, max_value=500, step=100)\n",
        "    #model.add(keras.layers.Dropout(0.2))\n",
        "    hp_layer_3 = hp.Int('layer_3', min_value=1, max_value=250, step=100)\n",
        "    hp_learning_rate = hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4])\n",
        "\n",
        "    model.add(tf.keras.layers.Dense(units=hp_layer_1, activation=hp_activation))\n",
        "    model.add(tf.keras.layers.Dense(units=hp_layer_2, activation=hp_activation))\n",
        "    model.add(tf.keras.layers.Dense(units=hp_layer_3, activation=hp_activation))\n",
        "    model.add(tf.keras.layers.Dense(2, activation='softmax'))\n",
        "\n",
        "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=hp_learning_rate),\n",
        "                loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
        "                metrics=['accuracy'])\n",
        "\n",
        "    return model\n",
        "def hypr_para_tuning(X, y):\n",
        "  # Hyperparameter tuning\n",
        "        tuner = kt.RandomSearch(\n",
        "            model_builder1,\n",
        "            objective='val_accuracy',\n",
        "            max_trials=5,###########################################################20\n",
        "            executions_per_trial=3,\n",
        "            #overwrite=True,\n",
        "            directory='DIR1',\n",
        "            project_name='tumor_vs_normal'\n",
        "        )\n",
        "        class PrintHyperparameters(tf.keras.callbacks.Callback):\n",
        "            def on_trial_begin(self, trial):\n",
        "                print(\"Trial hyperparameters:\", trial.hyperparameters.values)\n",
        "        tuner.search(X, y, epochs=20, validation_split = 0.2)   ########################100\n",
        "        best_model = tuner.get_best_models(num_models=1)[0]\n",
        "        best_hyperparameters = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
        "        print(f\"Best Hyperparameters: {best_hyperparameters}\")\n",
        "        print(best_model.summary())\n",
        "        print(f\"Best Validation Score: {np.max(tuner.results_summary())}\")\n",
        "        return best_model, best_hyperparameters\n"
      ],
      "metadata": {
        "id": "Tj8LGjSUitRh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Use the best hyperparameters found to train on the entire training dataset\n",
        "def train_final_model(X_train, y_train, X_val, y_val, final_best_hyperparameters,fold_no):\n",
        "    final_model = model_builder1(final_best_hyperparameters)\n",
        "    history = final_model.fit(X_train, y_train, epochs=300, validation_data=(X_val, y_val),verbose=0)\n",
        "    plt.figure(figsize=(12, 4))\n",
        "\n",
        "    # Accuracy plot\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
        "    plt.plot(history.history['val_accuracy'], label='Val Accuracy')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.legend()\n",
        "    plt.title('Training and Validation Accuracy')\n",
        "\n",
        "    # Loss plot\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(history.history['loss'], label='Train Loss')\n",
        "    plt.plot(history.history['val_loss'], label='Val Loss')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend()\n",
        "    plt.title('Training and Validation Loss')\n",
        "\n",
        "    # Save plot to file\n",
        "    plt.savefig(f'/content/drive/MyDrive/phd/pancan/Revised5/plots/accuracy_loss{fold_no}.png')\n",
        "    plt.close()\n",
        "\n",
        "    return final_model\n"
      ],
      "metadata": {
        "id": "dSCJcJBR0V4P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_model(X, y, n_splits=5):\n",
        "    # Hyperparameter tuning\n",
        "    best_model, best_hyperparameters = hypr_para_tuning(X, y)\n",
        "\n",
        "    # Evaluate the model\n",
        "    skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
        "    acc_scores, prec_scores, rec_scores, fpr_scores, fnr_scores = [], [], [], [], []\n",
        "    validation_losses = []\n",
        "    #best_hyperparameters = []\n",
        "    fold_thr = []\n",
        "    best_scores = []\n",
        "    f1s = []\n",
        "    fold_no = 1\n",
        "    data_to_write = ['fold_no', 'fold_accuracies','fold_loss', 'fold_precision', 'fold_recalls', 'fold_fpr', 'fold_fnr','fold_aucs','fold_f1','fold_thr']\n",
        "    for train_index, val_index in skf.split(X, y):\n",
        "      with open(results_file, mode='a', newline='') as file:\n",
        "        writer = csv.writer(file)\n",
        "        if file.tell() == 0:\n",
        "            writer.writerow(data_to_write)\n",
        "        X_train_fold, X_val_fold = X[train_index], X[val_index]\n",
        "        y_train_fold, y_val_fold = y[train_index], y[val_index]\n",
        "        #best_model.fit(X_train_fold, y_train_fold, epochs=300)\n",
        "        b_model = train_final_model(X_train_fold, y_train_fold, X_val_fold, y_val_fold, best_hyperparameters,fold_no)\n",
        "        val_loss, val_accuracy = b_model.evaluate(X_val_fold, y_val_fold)\n",
        "        validation_losses.append(val_loss)\n",
        "        y_pred_prob = b_model.predict(X_val_fold)\n",
        "        y_pred_prob = y_pred_prob[:, 1]\n",
        "        precision, recall, thresholds = precision_recall_curve(y_val_fold, y_pred_prob)\n",
        "\n",
        "        f1_scores = [f1_score(y_val_fold, y_pred_prob >= t) for t in thresholds]\n",
        "        optimal_idx = np.argmax(f1_scores)\n",
        "        f1 = f1_scores[optimal_idx]\n",
        "        f1s.append(f1)\n",
        "        optimal_threshold = thresholds[optimal_idx]\n",
        "        fold_thr.append(optimal_threshold)\n",
        "        y_pred = (y_pred_prob >= optimal_threshold).astype(int)\n",
        "\n",
        "        # Evaluate the model\n",
        "        #y_pred = np.argmax(best_model.predict(X_val_fold), axis=1)\n",
        "        acc = accuracy_score(y_val_fold, y_pred)\n",
        "        acc_scores.append(acc)\n",
        "        prec = precision_score(y_val_fold, y_pred)\n",
        "        prec_scores.append(prec)\n",
        "        rec = recall_score(y_val_fold, y_pred)\n",
        "        rec_scores.append(rec)\n",
        "        score = accuracy_score(y_val_fold, y_pred)\n",
        "        best_scores.append(score)\n",
        "        aucs = roc_auc_score(y_val_fold, y_pred)\n",
        "        # Confusion Matrix\n",
        "        tn, fp, fn, tp = confusion_matrix(y_val_fold, y_pred).ravel()\n",
        "        fpr = fp / (fp + tn)\n",
        "        fnr = fn / (fn + tp)\n",
        "        fpr_scores.append(fpr)\n",
        "        fnr_scores.append(fnr)\n",
        "        writer.writerow([fold_no, acc,val_loss, prec, rec,fpr, fnr, aucs,f1,optimal_threshold])\n",
        "\n",
        "\n",
        "        # ROC Curves\n",
        "        fpr, tpr, _ = roc_curve(y_val_fold, y_pred, pos_label=1)\n",
        "        plt.plot(fpr, tpr)\n",
        "        plt.xlabel('False Positive Rate')\n",
        "        plt.ylabel('True Positive Rate')\n",
        "        plt.title('ROC Curve')\n",
        "        plt.legend()\n",
        "        plt.savefig(f'/content/drive/MyDrive/phd/pancan/Revised5/plots/fpr_tpr{fold_no}.png')\n",
        "        plt.close()\n",
        "\n",
        "        plt.plot(recall, precision, marker='.')\n",
        "        plt.xlabel('Recall')\n",
        "        plt.ylabel('Precision')\n",
        "        plt.title('Precision-Recall Curve')\n",
        "        plt.legend()\n",
        "        plt.savefig(f'/content/drive/MyDrive/phd/pancan/Revised5/plots/rec_prec{fold_no}.png')\n",
        "        plt.close()\n",
        "        fold_no += 1\n",
        "\n",
        "\n",
        "    avg_threshold = np.mean(fold_thr)\n",
        "    print(f\"Average Accuracy: {np.mean(acc_scores)}\")\n",
        "    print(f\"Average Loss: {np.mean(validation_losses)}\")\n",
        "    print(f\"Average Precision: {np.mean(prec_scores)}\")\n",
        "    print(f\"Average Recall: {np.mean(rec_scores)}\")\n",
        "    print(f\"Average FPR: {np.mean(fpr_scores)}\")\n",
        "    print(f\"Average FNR: {np.mean(fnr_scores)}\")\n",
        "    print(f\"Average f1 score: {np.mean(f1s)}\")\n",
        "    print(f\"Average AUC: {np.mean(aucs)}\")\n",
        "    ## TRain final model\n",
        "    final_model = model_builder1(best_hyperparameters)\n",
        "    final_model.fit(X, y, epochs=300)\n",
        "    return final_model, avg_threshold"
      ],
      "metadata": {
        "id": "QBR7XVYqisbm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_test = y_test.astype(int)"
      ],
      "metadata": {
        "id": "51u2k09MajZJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_on_test_set(final_model, X_test, y_test, avg_threshold):\n",
        "\n",
        "    t_loss, t_acc = final_model.evaluate(X_test, y_test)\n",
        "    y_pred_probs = final_model.predict(X_test)  # Get predicted probabilities\n",
        "    y_pred = (y_pred_probs[:,1] >= avg_threshold).astype(int)\n",
        "    #y_pred = np.argmax(y_pred_probs, axis=1)  # Convert probabilities to class labels (0 or 1)\n",
        "    y_prob = y_pred_probs[:, 1]\n",
        "\n",
        "    # Calculate performance metrics\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    precision = precision_score(y_test, y_pred)\n",
        "    recall = recall_score(y_test, y_pred)\n",
        "    fpr, tpr, _ = roc_curve(y_test, y_prob, pos_label=1)\n",
        "    roc_auc = auc(fpr, tpr)\n",
        "\n",
        "    print(f\"Test Accuracy: {t_acc}\")\n",
        "    print(f\"Test Loss: {t_loss}\")\n",
        "    print(f\"Test Accuracy: {accuracy}\")\n",
        "    print(f\"Test Precision: {precision}\")\n",
        "    print(f\"Test Recall: {recall}\")\n",
        "    print(f\"Test ROC AUC: {roc_auc}\")\n",
        "    #print(f\"fpr{fpr}\")\n",
        "    #print(f\"tpr{tpr}\")\n",
        "   # tn, fp, fn, tp = confusion_matrix(X_test, y_test).ravel()\n",
        "    #fpr = fp / (fp + tn)\n",
        "    #fnr = fn / (fn + tp)\n",
        "\n",
        "    precision, recall, thresholds = precision_recall_curve(y_test, y_prob)\n",
        "    fnr = 1 - recall\n",
        "\n",
        "    # Select the threshold with the lowest FNR\n",
        "    optimal_idx = np.argmin(fnr)\n",
        "    optimal_threshold = thresholds[optimal_idx]\n",
        "    f1_scores = [f1_score(y_test, y_prob >= t) for t in thresholds]\n",
        "    optimal_idx = np.argmax(f1_scores)\n",
        "    f1 = f1_scores[optimal_idx]\n",
        "    #optimal_threshold = thresholds[optimal_idx]\n",
        "    #y_pred = (y_prob >= optimal_threshold).astype(int)\n",
        "\n",
        "   # print(f\"Test FPR: {fpr}\")\n",
        "   # print(f\"Test FNR: {fnr}\")\n",
        "    print(f\"Test f1 score: {f1}\")\n",
        "    print(f\"Test threshold: {optimal_threshold}\")\n",
        "    # Plot ROC Curve\n",
        "    '''\n",
        "    plt.figure()\n",
        "    plt.plot(fpr, tpr, label=f'ROC Curve (area = {roc_auc:.2f})')\n",
        "    plt.xlabel('False Positive Rate')\n",
        "    plt.ylabel('True Positive Rate')\n",
        "    plt.title('ROC Curve')\n",
        "    plt.legend(loc='lower right')\n",
        "    plt.grid(True)\n",
        "    plt.show()\n",
        "\n",
        "    # Plot Precision vs. Recall Curve\n",
        "    precision, recall, _ = precision_recall_curve(y_test, y_prob)\n",
        "    plt.figure()\n",
        "    plt.plot(recall, precision, marker='.')\n",
        "    plt.xlabel('Recall')\n",
        "    plt.ylabel('Precision')\n",
        "    plt.title('Precision vs. Recall Curve')\n",
        "    plt.grid(True)\n",
        "    plt.show()\n",
        "'''\n",
        "    cm = confusion_matrix(y_test,y_pred)\n",
        "    class_names = ['Normal', 'Tumor']  # Assuming 'Tumor' is the positive class\n",
        "\n",
        "    # Create a heatmap\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=class_names, yticklabels=class_names)\n",
        "    plt.xlabel('Predicted')\n",
        "    plt.ylabel('Actual')\n",
        "    plt.title('Confusion Matrix Heatmap')\n",
        "    plt.show()\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "9DalPUiU0quh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_model, avg_threshold = evaluate_model(X_train, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Lcm4TqcL3HY0",
        "outputId": "66d4b575-317f-435b-8229-3b3d588e441d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 5 Complete [00h 00m 52s]\n",
            "val_accuracy: 0.9192506670951843\n",
            "\n",
            "Best val_accuracy So Far: 0.9812661409378052\n",
            "Total elapsed time: 00h 04m 17s\n",
            "Best Hyperparameters: <keras_tuner.src.engine.hyperparameters.hyperparameters.HyperParameters object at 0x7f58af271270>\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m115\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m501\u001b[0m)                 │          \u001b[38;5;34m58,116\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m201\u001b[0m)                 │         \u001b[38;5;34m100,902\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m201\u001b[0m)                 │          \u001b[38;5;34m40,602\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m)                   │             \u001b[38;5;34m404\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">115</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">501</span>)                 │          <span style=\"color: #00af00; text-decoration-color: #00af00\">58,116</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">201</span>)                 │         <span style=\"color: #00af00; text-decoration-color: #00af00\">100,902</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">201</span>)                 │          <span style=\"color: #00af00; text-decoration-color: #00af00\">40,602</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)                   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">404</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m200,024\u001b[0m (781.34 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">200,024</span> (781.34 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m200,024\u001b[0m (781.34 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">200,024</span> (781.34 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "None\n",
            "Results summary\n",
            "Results in DIR1/tumor_vs_normal\n",
            "Showing 10 best trials\n",
            "Objective(name=\"val_accuracy\", direction=\"max\")\n",
            "\n",
            "Trial 1 summary\n",
            "Hyperparameters:\n",
            "activation: tanh\n",
            "layer_1: 501\n",
            "layer_2: 201\n",
            "layer_3: 201\n",
            "learning_rate: 0.001\n",
            "Score: 0.9812661409378052\n",
            "\n",
            "Trial 0 summary\n",
            "Hyperparameters:\n",
            "activation: tanh\n",
            "layer_1: 701\n",
            "layer_2: 101\n",
            "layer_3: 101\n",
            "learning_rate: 0.001\n",
            "Score: 0.9806201457977295\n",
            "\n",
            "Trial 2 summary\n",
            "Hyperparameters:\n",
            "activation: tanh\n",
            "layer_1: 201\n",
            "layer_2: 201\n",
            "layer_3: 1\n",
            "learning_rate: 0.01\n",
            "Score: 0.9192506670951843\n",
            "\n",
            "Trial 3 summary\n",
            "Hyperparameters:\n",
            "activation: tanh\n",
            "layer_1: 601\n",
            "layer_2: 1\n",
            "layer_3: 101\n",
            "learning_rate: 0.001\n",
            "Score: 0.9192506670951843\n",
            "\n",
            "Trial 4 summary\n",
            "Hyperparameters:\n",
            "activation: relu\n",
            "layer_1: 701\n",
            "layer_2: 1\n",
            "layer_3: 201\n",
            "learning_rate: 0.01\n",
            "Score: 0.9192506670951843\n",
            "Best Validation Score: None\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9851 - loss: 0.0600\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:matplotlib.legend:No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n",
            "WARNING:matplotlib.legend:No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9747 - loss: 0.0866\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:matplotlib.legend:No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n",
            "WARNING:matplotlib.legend:No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9810 - loss: 0.0809\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:matplotlib.legend:No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n",
            "WARNING:matplotlib.legend:No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9857 - loss: 0.0683\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:matplotlib.legend:No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n",
            "WARNING:matplotlib.legend:No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9796 - loss: 0.0862\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:matplotlib.legend:No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n",
            "WARNING:matplotlib.legend:No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average Accuracy: 0.9834625322997417\n",
            "Average Loss: 0.07973979488015175\n",
            "Average Precision: 0.9892838259799716\n",
            "Average Recall: 0.9930924908459874\n",
            "Average FPR: 0.15532673267326733\n",
            "Average FNR: 0.006907509154012684\n",
            "Average f1 score: 0.9911743654952216\n",
            "Average AUC: 0.9134227866463218\n",
            "Epoch 1/300\n",
            "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - accuracy: 0.9316 - loss: 0.1935\n",
            "Epoch 2/300\n",
            "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9738 - loss: 0.0745\n",
            "Epoch 3/300\n",
            "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9784 - loss: 0.0678\n",
            "Epoch 4/300\n",
            "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9761 - loss: 0.0661\n",
            "Epoch 5/300\n",
            "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9731 - loss: 0.0698\n",
            "Epoch 6/300\n",
            "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9778 - loss: 0.0665\n",
            "Epoch 7/300\n",
            "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9803 - loss: 0.0585\n",
            "Epoch 8/300\n",
            "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9810 - loss: 0.0558\n",
            "Epoch 9/300\n",
            "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9809 - loss: 0.0576\n",
            "Epoch 10/300\n",
            "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9784 - loss: 0.0602\n",
            "Epoch 11/300\n",
            "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9752 - loss: 0.0749\n",
            "Epoch 12/300\n",
            "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9772 - loss: 0.0651\n",
            "Epoch 13/300\n",
            "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9764 - loss: 0.0703\n",
            "Epoch 14/300\n",
            "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9792 - loss: 0.0605\n",
            "Epoch 15/300\n",
            "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9735 - loss: 0.0733\n",
            "Epoch 16/300\n",
            "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9831 - loss: 0.0477\n",
            "Epoch 17/300\n",
            "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9828 - loss: 0.0571\n",
            "Epoch 18/300\n",
            "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9757 - loss: 0.0665\n",
            "Epoch 19/300\n",
            "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9784 - loss: 0.0641\n",
            "Epoch 20/300\n",
            "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9799 - loss: 0.0641\n",
            "Epoch 21/300\n",
            "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9783 - loss: 0.0663\n",
            "Epoch 22/300\n",
            "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9754 - loss: 0.0673\n",
            "Epoch 23/300\n",
            "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9825 - loss: 0.0570\n",
            "Epoch 24/300\n",
            "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9799 - loss: 0.0658\n",
            "Epoch 25/300\n",
            "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9842 - loss: 0.0514\n",
            "Epoch 26/300\n",
            "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9814 - loss: 0.0588\n",
            "Epoch 27/300\n",
            "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9835 - loss: 0.0523\n",
            "Epoch 28/300\n",
            "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9834 - loss: 0.0500\n",
            "Epoch 29/300\n",
            "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9824 - loss: 0.0547\n",
            "Epoch 30/300\n",
            "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9837 - loss: 0.0510\n",
            "Epoch 31/300\n",
            "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9837 - loss: 0.0507\n",
            "Epoch 32/300\n",
            "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9838 - loss: 0.0510\n",
            "Epoch 33/300\n",
            "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9834 - loss: 0.0484\n",
            "Epoch 34/300\n",
            "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9820 - loss: 0.0509\n",
            "Epoch 35/300\n",
            "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9842 - loss: 0.0511\n",
            "Epoch 36/300\n",
            "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9860 - loss: 0.0472\n",
            "Epoch 37/300\n",
            "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9821 - loss: 0.0553\n",
            "Epoch 38/300\n",
            "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9868 - loss: 0.0475\n",
            "Epoch 39/300\n",
            "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9830 - loss: 0.0531\n",
            "Epoch 40/300\n",
            "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9858 - loss: 0.0457\n",
            "Epoch 41/300\n",
            "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9841 - loss: 0.0505\n",
            "Epoch 42/300\n",
            "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9833 - loss: 0.0496\n",
            "Epoch 43/300\n",
            "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9861 - loss: 0.0429\n",
            "Epoch 44/300\n",
            "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9822 - loss: 0.0504\n",
            "Epoch 45/300\n",
            "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9843 - loss: 0.0542\n",
            "Epoch 46/300\n",
            "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9820 - loss: 0.0558\n",
            "Epoch 47/300\n",
            "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9845 - loss: 0.0489\n",
            "Epoch 48/300\n",
            "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9826 - loss: 0.0534\n",
            "Epoch 49/300\n",
            "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9846 - loss: 0.0518\n",
            "Epoch 50/300\n",
            "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9863 - loss: 0.0470\n",
            "Epoch 51/300\n",
            "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9846 - loss: 0.0515\n",
            "Epoch 52/300\n",
            "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9847 - loss: 0.0489\n",
            "Epoch 53/300\n",
            "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9822 - loss: 0.0591\n",
            "Epoch 54/300\n",
            "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9845 - loss: 0.0493\n",
            "Epoch 55/300\n",
            "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9815 - loss: 0.0648\n",
            "Epoch 56/300\n",
            "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9854 - loss: 0.0452\n",
            "Epoch 57/300\n",
            "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9866 - loss: 0.0447\n",
            "Epoch 58/300\n",
            "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9891 - loss: 0.0434\n",
            "Epoch 59/300\n",
            "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9854 - loss: 0.0468\n",
            "Epoch 60/300\n",
            "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9859 - loss: 0.0469\n",
            "Epoch 61/300\n",
            "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9874 - loss: 0.0448\n",
            "Epoch 62/300\n",
            "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9886 - loss: 0.0424\n",
            "Epoch 63/300\n",
            "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9875 - loss: 0.0433\n",
            "Epoch 64/300\n",
            "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9865 - loss: 0.0440\n",
            "Epoch 65/300\n",
            "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9888 - loss: 0.0399\n",
            "Epoch 66/300\n",
            "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9896 - loss: 0.0403\n",
            "Epoch 67/300\n",
            "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9816 - loss: 0.0593\n",
            "Epoch 68/300\n",
            "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9875 - loss: 0.0450\n",
            "Epoch 69/300\n",
            "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9864 - loss: 0.0436\n",
            "Epoch 70/300\n",
            "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9870 - loss: 0.0530\n",
            "Epoch 71/300\n",
            "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9815 - loss: 0.0558\n",
            "Epoch 72/300\n",
            "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9883 - loss: 0.0409\n",
            "Epoch 73/300\n",
            "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9864 - loss: 0.0407\n",
            "Epoch 74/300\n",
            "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9859 - loss: 0.0410\n",
            "Epoch 75/300\n",
            "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9834 - loss: 0.0520\n",
            "Epoch 76/300\n",
            "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9848 - loss: 0.0441\n",
            "Epoch 77/300\n",
            "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9881 - loss: 0.0413\n",
            "Epoch 78/300\n",
            "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9884 - loss: 0.0396\n",
            "Epoch 79/300\n",
            "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9890 - loss: 0.0388\n",
            "Epoch 80/300\n",
            "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9820 - loss: 0.0533\n",
            "Epoch 81/300\n",
            "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9846 - loss: 0.0516\n",
            "Epoch 82/300\n",
            "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9871 - loss: 0.0450\n",
            "Epoch 83/300\n",
            "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9849 - loss: 0.0483\n",
            "Epoch 84/300\n",
            "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9879 - loss: 0.0418\n",
            "Epoch 85/300\n",
            "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9862 - loss: 0.0462\n",
            "Epoch 86/300\n",
            "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9820 - loss: 0.0550\n",
            "Epoch 87/300\n",
            "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9864 - loss: 0.0441\n",
            "Epoch 88/300\n",
            "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9834 - loss: 0.0504\n",
            "Epoch 89/300\n",
            "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9860 - loss: 0.0429\n",
            "Epoch 90/300\n",
            "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9859 - loss: 0.0477\n",
            "Epoch 91/300\n",
            "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9891 - loss: 0.0376\n",
            "Epoch 92/300\n",
            "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9824 - loss: 0.0544\n",
            "Epoch 93/300\n",
            "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9839 - loss: 0.0504\n",
            "Epoch 94/300\n",
            "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9865 - loss: 0.0403\n",
            "Epoch 95/300\n",
            "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9890 - loss: 0.0384\n",
            "Epoch 96/300\n",
            "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9858 - loss: 0.0441\n",
            "Epoch 97/300\n",
            "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9904 - loss: 0.0323\n",
            "Epoch 98/300\n",
            "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9869 - loss: 0.0420\n",
            "Epoch 99/300\n",
            "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9871 - loss: 0.0419\n",
            "Epoch 100/300\n",
            "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9868 - loss: 0.0392\n",
            "Epoch 101/300\n",
            "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9883 - loss: 0.0387\n",
            "Epoch 102/300\n",
            "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9829 - loss: 0.0507\n",
            "Epoch 103/300\n",
            "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9899 - loss: 0.0388\n",
            "Epoch 104/300\n",
            "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9874 - loss: 0.0464\n",
            "Epoch 105/300\n",
            "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9889 - loss: 0.0399\n",
            "Epoch 106/300\n",
            "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9865 - loss: 0.0421\n",
            "Epoch 107/300\n",
            "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9866 - loss: 0.0419\n",
            "Epoch 108/300\n",
            "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9870 - loss: 0.0450\n",
            "Epoch 109/300\n",
            "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9854 - loss: 0.0437\n",
            "Epoch 110/300\n",
            "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9885 - loss: 0.0368\n",
            "Epoch 111/300\n",
            "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9868 - loss: 0.0424\n",
            "Epoch 112/300\n",
            "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9888 - loss: 0.0403\n",
            "Epoch 113/300\n",
            "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9872 - loss: 0.0416\n",
            "Epoch 114/300\n",
            "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9855 - loss: 0.0458\n",
            "Epoch 115/300\n",
            "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9885 - loss: 0.0429\n",
            "Epoch 116/300\n",
            "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9881 - loss: 0.0388\n",
            "Epoch 117/300\n",
            "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9884 - loss: 0.0387\n",
            "Epoch 118/300\n",
            "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9850 - loss: 0.0501\n",
            "Epoch 119/300\n",
            "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9883 - loss: 0.0456\n",
            "Epoch 120/300\n",
            "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9854 - loss: 0.0472\n",
            "Epoch 121/300\n",
            "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9876 - loss: 0.0422\n",
            "Epoch 122/300\n",
            "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9845 - loss: 0.0511\n",
            "Epoch 123/300\n",
            "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9872 - loss: 0.0444\n",
            "Epoch 124/300\n",
            "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9873 - loss: 0.0460\n",
            "Epoch 125/300\n",
            "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9869 - loss: 0.0425\n",
            "Epoch 126/300\n",
            "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9883 - loss: 0.0401\n",
            "Epoch 127/300\n",
            "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9857 - loss: 0.0444\n",
            "Epoch 128/300\n",
            "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9875 - loss: 0.0448\n",
            "Epoch 129/300\n",
            "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9861 - loss: 0.0440\n",
            "Epoch 130/300\n",
            "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9885 - loss: 0.0432\n",
            "Epoch 131/300\n",
            "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9863 - loss: 0.0436\n",
            "Epoch 132/300\n",
            "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9826 - loss: 0.0491\n",
            "Epoch 133/300\n",
            "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9794 - loss: 0.0632\n",
            "Epoch 134/300\n",
            "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9903 - loss: 0.0377\n",
            "Epoch 135/300\n",
            "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9822 - loss: 0.0517\n",
            "Epoch 136/300\n",
            "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9875 - loss: 0.0430\n",
            "Epoch 137/300\n",
            "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9875 - loss: 0.0416\n",
            "Epoch 138/300\n",
            "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9874 - loss: 0.0431\n",
            "Epoch 139/300\n",
            "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9883 - loss: 0.0419\n",
            "Epoch 140/300\n",
            "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9865 - loss: 0.0459\n",
            "Epoch 141/300\n",
            "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9861 - loss: 0.0463\n",
            "Epoch 142/300\n",
            "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9844 - loss: 0.0511\n",
            "Epoch 143/300\n",
            "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9833 - loss: 0.0461\n",
            "Epoch 144/300\n",
            "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9880 - loss: 0.0439\n",
            "Epoch 145/300\n",
            "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9904 - loss: 0.0366\n",
            "Epoch 146/300\n",
            "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9887 - loss: 0.0413\n",
            "Epoch 147/300\n",
            "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9894 - loss: 0.0384\n",
            "Epoch 148/300\n",
            "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9877 - loss: 0.0442\n",
            "Epoch 149/300\n",
            "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9869 - loss: 0.0454\n",
            "Epoch 150/300\n",
            "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9881 - loss: 0.0400\n",
            "Epoch 151/300\n",
            "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9888 - loss: 0.0435\n",
            "Epoch 152/300\n",
            "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9886 - loss: 0.0378\n",
            "Epoch 153/300\n",
            "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9907 - loss: 0.0334\n",
            "Epoch 154/300\n",
            "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9820 - loss: 0.0532\n",
            "Epoch 155/300\n",
            "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9849 - loss: 0.0484\n",
            "Epoch 156/300\n",
            "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9795 - loss: 0.0550\n",
            "Epoch 157/300\n",
            "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9882 - loss: 0.0412\n",
            "Epoch 158/300\n",
            "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9837 - loss: 0.0520\n",
            "Epoch 159/300\n",
            "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9896 - loss: 0.0375\n",
            "Epoch 160/300\n",
            "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9888 - loss: 0.0412\n",
            "Epoch 161/300\n",
            "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9884 - loss: 0.0403\n",
            "Epoch 162/300\n",
            "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9920 - loss: 0.0315\n",
            "Epoch 163/300\n",
            "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9828 - loss: 0.0417\n",
            "Epoch 164/300\n",
            "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9854 - loss: 0.0454\n",
            "Epoch 165/300\n",
            "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9899 - loss: 0.0398\n",
            "Epoch 166/300\n",
            "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9891 - loss: 0.0397\n",
            "Epoch 167/300\n",
            "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9882 - loss: 0.0418\n",
            "Epoch 168/300\n",
            "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9877 - loss: 0.0383\n",
            "Epoch 169/300\n",
            "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9880 - loss: 0.0426\n",
            "Epoch 170/300\n",
            "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9890 - loss: 0.0368\n",
            "Epoch 171/300\n",
            "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9913 - loss: 0.0338\n",
            "Epoch 172/300\n",
            "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9816 - loss: 0.0528\n",
            "Epoch 173/300\n",
            "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9889 - loss: 0.0414\n",
            "Epoch 174/300\n",
            "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9909 - loss: 0.0365\n",
            "Epoch 175/300\n",
            "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9842 - loss: 0.0489\n",
            "Epoch 176/300\n",
            "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9919 - loss: 0.0327\n",
            "Epoch 177/300\n",
            "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9891 - loss: 0.0384\n",
            "Epoch 178/300\n",
            "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9897 - loss: 0.0355\n",
            "Epoch 179/300\n",
            "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9844 - loss: 0.0500\n",
            "Epoch 180/300\n",
            "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9904 - loss: 0.0347\n",
            "Epoch 181/300\n",
            "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9885 - loss: 0.0419\n",
            "Epoch 182/300\n",
            "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9899 - loss: 0.0379\n",
            "Epoch 183/300\n",
            "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9867 - loss: 0.0442\n",
            "Epoch 184/300\n",
            "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9876 - loss: 0.0411\n",
            "Epoch 185/300\n",
            "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9908 - loss: 0.0348\n",
            "Epoch 186/300\n",
            "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9915 - loss: 0.0308\n",
            "Epoch 187/300\n",
            "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9904 - loss: 0.0325\n",
            "Epoch 188/300\n",
            "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9884 - loss: 0.0378\n",
            "Epoch 189/300\n",
            "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9910 - loss: 0.0343\n",
            "Epoch 190/300\n",
            "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9789 - loss: 0.0575\n",
            "Epoch 191/300\n",
            "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9902 - loss: 0.0337\n",
            "Epoch 192/300\n",
            "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9879 - loss: 0.0426\n",
            "Epoch 193/300\n",
            "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9886 - loss: 0.0396\n",
            "Epoch 194/300\n",
            "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9905 - loss: 0.0361\n",
            "Epoch 195/300\n",
            "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9903 - loss: 0.0385\n",
            "Epoch 196/300\n",
            "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9914 - loss: 0.0342\n",
            "Epoch 197/300\n",
            "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9890 - loss: 0.0411\n",
            "Epoch 198/300\n",
            "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9880 - loss: 0.0462\n",
            "Epoch 199/300\n",
            "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9869 - loss: 0.0437\n",
            "Epoch 200/300\n",
            "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9916 - loss: 0.0334\n",
            "Epoch 201/300\n",
            "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9903 - loss: 0.0389\n",
            "Epoch 202/300\n",
            "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9861 - loss: 0.0429\n",
            "Epoch 203/300\n",
            "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9890 - loss: 0.0430\n",
            "Epoch 204/300\n",
            "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9867 - loss: 0.0446\n",
            "Epoch 205/300\n",
            "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9915 - loss: 0.0362\n",
            "Epoch 206/300\n",
            "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9908 - loss: 0.0371\n",
            "Epoch 207/300\n",
            "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9835 - loss: 0.0499\n",
            "Epoch 208/300\n",
            "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9867 - loss: 0.0412\n",
            "Epoch 209/300\n",
            "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9910 - loss: 0.0350\n",
            "Epoch 210/300\n",
            "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9882 - loss: 0.0469\n",
            "Epoch 211/300\n",
            "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9910 - loss: 0.0380\n",
            "Epoch 212/300\n",
            "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9899 - loss: 0.0389\n",
            "Epoch 213/300\n",
            "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9901 - loss: 0.0386\n",
            "Epoch 214/300\n",
            "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9807 - loss: 0.0516\n",
            "Epoch 215/300\n",
            "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9899 - loss: 0.0359\n",
            "Epoch 216/300\n",
            "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9914 - loss: 0.0336\n",
            "Epoch 217/300\n",
            "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9896 - loss: 0.0364\n",
            "Epoch 218/300\n",
            "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9917 - loss: 0.0305\n",
            "Epoch 219/300\n",
            "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9925 - loss: 0.0303\n",
            "Epoch 220/300\n",
            "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9916 - loss: 0.0314\n",
            "Epoch 221/300\n",
            "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9919 - loss: 0.0348\n",
            "Epoch 222/300\n",
            "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9853 - loss: 0.0469\n",
            "Epoch 223/300\n",
            "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9893 - loss: 0.0355\n",
            "Epoch 224/300\n",
            "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9913 - loss: 0.0319\n",
            "Epoch 225/300\n",
            "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9850 - loss: 0.0459\n",
            "Epoch 226/300\n",
            "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9854 - loss: 0.0454\n",
            "Epoch 227/300\n",
            "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9791 - loss: 0.0698\n",
            "Epoch 228/300\n",
            "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9828 - loss: 0.0547\n",
            "Epoch 229/300\n",
            "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9843 - loss: 0.0550\n",
            "Epoch 230/300\n",
            "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9839 - loss: 0.0480\n",
            "Epoch 231/300\n",
            "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9863 - loss: 0.0443\n",
            "Epoch 232/300\n",
            "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9845 - loss: 0.0472\n",
            "Epoch 233/300\n",
            "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9815 - loss: 0.0567\n",
            "Epoch 234/300\n",
            "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9861 - loss: 0.0422\n",
            "Epoch 235/300\n",
            "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9871 - loss: 0.0452\n",
            "Epoch 236/300\n",
            "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9890 - loss: 0.0386\n",
            "Epoch 237/300\n",
            "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9796 - loss: 0.0557\n",
            "Epoch 238/300\n",
            "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9875 - loss: 0.0449\n",
            "Epoch 239/300\n",
            "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9881 - loss: 0.0445\n",
            "Epoch 240/300\n",
            "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9859 - loss: 0.0409\n",
            "Epoch 241/300\n",
            "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9887 - loss: 0.0396\n",
            "Epoch 242/300\n",
            "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9891 - loss: 0.0402\n",
            "Epoch 243/300\n",
            "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9895 - loss: 0.0378\n",
            "Epoch 244/300\n",
            "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9844 - loss: 0.0427\n",
            "Epoch 245/300\n",
            "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9862 - loss: 0.0445\n",
            "Epoch 246/300\n",
            "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9915 - loss: 0.0323\n",
            "Epoch 247/300\n",
            "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9905 - loss: 0.0372\n",
            "Epoch 248/300\n",
            "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9852 - loss: 0.0458\n",
            "Epoch 249/300\n",
            "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9884 - loss: 0.0386\n",
            "Epoch 250/300\n",
            "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9901 - loss: 0.0333\n",
            "Epoch 251/300\n",
            "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9894 - loss: 0.0392\n",
            "Epoch 252/300\n",
            "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9912 - loss: 0.0323\n",
            "Epoch 253/300\n",
            "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9886 - loss: 0.0369\n",
            "Epoch 254/300\n",
            "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9858 - loss: 0.0458\n",
            "Epoch 255/300\n",
            "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9878 - loss: 0.0377\n",
            "Epoch 256/300\n",
            "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9852 - loss: 0.0474\n",
            "Epoch 257/300\n",
            "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9804 - loss: 0.0534\n",
            "Epoch 258/300\n",
            "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9817 - loss: 0.0485\n",
            "Epoch 259/300\n",
            "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9790 - loss: 0.0509\n",
            "Epoch 260/300\n",
            "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9882 - loss: 0.0401\n",
            "Epoch 261/300\n",
            "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9884 - loss: 0.0355\n",
            "Epoch 262/300\n",
            "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9870 - loss: 0.0390\n",
            "Epoch 263/300\n",
            "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9884 - loss: 0.0435\n",
            "Epoch 264/300\n",
            "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9840 - loss: 0.0465\n",
            "Epoch 265/300\n",
            "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9843 - loss: 0.0480\n",
            "Epoch 266/300\n",
            "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9875 - loss: 0.0374\n",
            "Epoch 267/300\n",
            "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9798 - loss: 0.0571\n",
            "Epoch 268/300\n",
            "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9832 - loss: 0.0531\n",
            "Epoch 269/300\n",
            "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9900 - loss: 0.0363\n",
            "Epoch 270/300\n",
            "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9878 - loss: 0.0445\n",
            "Epoch 271/300\n",
            "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9880 - loss: 0.0369\n",
            "Epoch 272/300\n",
            "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9892 - loss: 0.0331\n",
            "Epoch 273/300\n",
            "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9896 - loss: 0.0357\n",
            "Epoch 274/300\n",
            "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9900 - loss: 0.0379\n",
            "Epoch 275/300\n",
            "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9869 - loss: 0.0421\n",
            "Epoch 276/300\n",
            "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9902 - loss: 0.0323\n",
            "Epoch 277/300\n",
            "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9929 - loss: 0.0291\n",
            "Epoch 278/300\n",
            "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9828 - loss: 0.0480\n",
            "Epoch 279/300\n",
            "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9851 - loss: 0.0410\n",
            "Epoch 280/300\n",
            "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9879 - loss: 0.0409\n",
            "Epoch 281/300\n",
            "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9903 - loss: 0.0290\n",
            "Epoch 282/300\n",
            "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9853 - loss: 0.0445\n",
            "Epoch 283/300\n",
            "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9900 - loss: 0.0344\n",
            "Epoch 284/300\n",
            "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9869 - loss: 0.0383\n",
            "Epoch 285/300\n",
            "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9859 - loss: 0.0446\n",
            "Epoch 286/300\n",
            "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9899 - loss: 0.0305\n",
            "Epoch 287/300\n",
            "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9889 - loss: 0.0359\n",
            "Epoch 288/300\n",
            "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9915 - loss: 0.0314\n",
            "Epoch 289/300\n",
            "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9849 - loss: 0.0436\n",
            "Epoch 290/300\n",
            "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9915 - loss: 0.0338\n",
            "Epoch 291/300\n",
            "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9887 - loss: 0.0365\n",
            "Epoch 292/300\n",
            "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9906 - loss: 0.0362\n",
            "Epoch 293/300\n",
            "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9879 - loss: 0.0390\n",
            "Epoch 294/300\n",
            "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9915 - loss: 0.0325\n",
            "Epoch 295/300\n",
            "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9838 - loss: 0.0498\n",
            "Epoch 296/300\n",
            "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9789 - loss: 0.0503\n",
            "Epoch 297/300\n",
            "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9766 - loss: 0.0577\n",
            "Epoch 298/300\n",
            "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9839 - loss: 0.0449\n",
            "Epoch 299/300\n",
            "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9849 - loss: 0.0409\n",
            "Epoch 300/300\n",
            "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9894 - loss: 0.0329\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "avg_threshold"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9zRFfYL7uaHX",
        "outputId": "8454646a-2f9a-44ff-8488-266db284db49"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.25723308"
            ]
          },
          "metadata": {},
          "execution_count": 159
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "evaluate_on_test_set(final_model, X_test, y_test, avg_threshold)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 710
        },
        "id": "hQQ5b_d9lkkB",
        "outputId": "e90099d2-4a2e-4e83-a6f5-9aade757967a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9709 - loss: 0.0839\n",
            "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
            "Test Accuracy: 0.9710668921470642\n",
            "Test Loss: 0.07962624728679657\n",
            "Test Accuracy: 0.9671488848704038\n",
            "Test Precision: 0.9676812048948855\n",
            "Test Recall: 0.9980582524271845\n",
            "Test ROC AUC: 0.9753690455913246\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x600 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "final_model.save(\"final_model.h5\")"
      ],
      "metadata": {
        "id": "zdtCIwHP1JcW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "75e68525-2b0f-4f75-8867-29dddec6007b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Wn8L6YiD1JgD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lw1EIeIbbcap"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MoTosN0ubcd2"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tmCx2BXkbchw"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lpNzcqORbHCG"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "53ZesVTBbBWd"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nN_sqoGMbBZ3"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lOt5PUjObBdb"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XZmt1CvipZbn"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}